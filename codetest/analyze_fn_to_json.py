# analyze_phrase_to_json.py
import os, re, json, argparse
from typing import List, Dict, Any
from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer
from interlinked_local import AI

QDRANT_URL   = "http://127.0.0.1:6333"
COLLECTION   = "code_index"
EMBED_MODEL  = "all-MiniLM-L6-v2"

def get_client() -> QdrantClient:
    return QdrantClient(url=QDRANT_URL)

def embedder():
    return SentenceTransformer(EMBED_MODEL)

def clip(s: str, n=1200) -> str:
    s = s or ""
    return s if len(s) <= n else s[:n] + "\n/* ...clip... */"

def extract_called_functions(code: str, func_name: str) -> List[str]:
    if not code:
        return []
    body = code.split("{", 1)[-1] if "{" in code else code
    names = set(re.findall(r"\b([A-Za-z_]\w*)\s*\(", body))
    blacklist = {"if","for","while","switch","return","sizeof","catch","else","case"}
    return sorted([n for n in names if n not in blacklist and n != func_name])

def extract_params(code: str, func_name: str) -> List[Dict[str, str]]:
    params = []
    if not code:
        return params
    head = code.split("{", 1)[0]
    m = re.search(rf"{re.escape(func_name)}\s*\((.*?)\)", head, re.S)
    if not m:
        return params
    param_str = m.group(1).strip()
    if not param_str or param_str.lower() == "void":
        return params
    for p in re.split(r",\s*", param_str):
        p = re.sub(r"\s*=\s*[^,]+$", "", p)  # å»é»˜è®¤å€¼
        parts = p.strip().split()
        if parts:
            name = re.sub(r"[*&\[\]]", "", parts[-1])
            typ  = " ".join(parts[:-1]) or parts[-1]
            params.append({"name": name, "type": typ, "meaning": ""})
    return params

def exact_phrase_hits(c: QdrantClient, phrase: str, page: int = 200, cap: int = 30) -> List[Dict[str, Any]]:
    flt = models.Filter(must=[models.FieldCondition(
        key="content",
        match=models.MatchText(text=phrase)
    )])

    hits, next_page = [], None
    while True and len(hits) < cap:
        points, next_page = c.scroll(
            collection_name=COLLECTION,
            limit=page,
            with_payload=True,
            with_vectors=False,
            offset=next_page,
            scroll_filter=flt,
        )
        if not points:
            break

        for pt in points:
            pl = pt.payload or {}
            code = pl.get("content") or ""
            if re.search(re.escape(phrase), code, flags=re.IGNORECASE):
                hits.append(pl)
                if len(hits) >= cap:
                    break

        if next_page is None:
            break

    return hits

def build_snippet_around_phrase(code: str, phrase: str, ctx_lines: int = 2) -> str:
    if not code:
        return ""
    lines = code.splitlines()
    for idx, line in enumerate(lines):
        if re.search(re.escape(phrase), line, flags=re.IGNORECASE):
            start = max(0, idx - ctx_lines)
            end   = min(len(lines), idx + ctx_lines + 1)
            return "\n".join(lines[start:end])
    return clip(code, 400)

def build_prompt(phrase: str, items: List[Dict[str, Any]], question: str = None) -> str:
    entries = []
    for it in items:
        entries.append(
f"""### ITEM
Function: {it.get('function_name')}
File: {it.get('file')}:{it.get('start_line')}-{it.get('end_line')}

ParamsGuess: {json.dumps(it.get('params_guess', []), ensure_ascii=False)}
CallsGuess: {json.dumps(it.get('calls_guess', []), ensure_ascii=False)}

Snippet:
{it.get('snippet')}
"""
        )
    joined = "\n\n".join(entries)
    qline = f"é—®é¢˜åœºæ™¯ï¼š{question}\n" if question else ""

    return f"""
ä½ æ˜¯èµ„æ·±åµŒå…¥å¼/C++ä»£ç åˆ†æåŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯ä»£ç åº“ä¸­**ç²¾ç¡®åŒ…å«çŸ­è¯­**â€œ{phrase}â€çš„å‡½æ•°æˆ–è°ƒç”¨ç‚¹ç‰‡æ®µï¼ˆå‡æ¥æºäºå‘é‡æ•°æ®åº“æœåŠ¡ç«¯è¿‡æ»¤+å®¢æˆ·ç«¯äºŒæ¬¡æ ¡éªŒï¼‰ã€‚{qline}
è¯·åŸºäºæ¯ä¸ªæ¡ç›®çš„ç‰‡æ®µï¼ˆä»¥åŠç»™å‡ºçš„å‚æ•°/è¢«è°ƒå‡½æ•°çŒœæµ‹ï¼‰ï¼Œåˆ†æè¯¥å‡½æ•°åœ¨ä»£ç åº“ä¸­çš„å·¥ä½œæµç¨‹ï¼Œå¹¶è¾“å‡º**ä¸¥æ ¼ JSON**ï¼Œä»…è¿”å› JSONã€ä¸è¦ Markdownã€‚

ä¸Šä¸‹æ–‡æ¡ç›®ï¼ˆè‹¥å¹²ï¼‰ï¼š
{joined}

å¿…é¡»è¿”å›çš„ JSON ç»“æ„ï¼ˆæ•°ç»„ï¼‰ï¼šä¾‹å¦‚
[
  {{
    "function_name": "",
    "location": "{{file}}:{{start_line}}-{{end_line}}",
    "role": "è¯¥å‡½æ•°/è°ƒç”¨åœ¨ç³»ç»Ÿä¸­çš„èŒè´£ï¼ˆ1-2å¥ï¼‰",
    "parameters": [{{"name":"","type":"","meaning":""}}],
    "called_functions": [],
    "logic_flow": ["æŒ‰æ‰§è¡Œå…ˆååˆ—æ­¥éª¤ï¼ˆå°½é‡å…·ä½“åˆ°æ¡ä»¶/çŠ¶æ€/è°ƒç”¨ï¼‰"],
    "possible_causes": ["ä¸çŸ­è¯­ç›¸å…³çš„â€œä¸åæ•°æ®/æ— è¾“å‡ºâ€ç­‰å¯èƒ½åŸå› ï¼ˆè‹¥é€‚ç”¨ï¼‰"],
    "diagnostics": ["å¯éªŒè¯çš„æ’æŸ¥å»ºè®®ï¼ˆæ—¥å¿—/å¯„å­˜å™¨/çŠ¶æ€ä½/è¾¹ç•Œæ¡ä»¶ç­‰ï¼‰"]
  }}
]

ä¸¥æ ¼è¦æ±‚ï¼š
- ä»…è¾“å‡º JSONï¼Œä¸”æ˜¯ä¸€ä¸ª JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªå‘½ä¸­çš„æ¡ç›®
- è‹¥ä¿¡æ¯ä¸è¶³ï¼Œè¯·å°½é‡ä¾æ®ç‰‡æ®µæ¨æ–­ï¼Œä½†ä¸è¦è™šæ„ä¸å­˜åœ¨çš„ API/ç¡¬ä»¶å¯„å­˜å™¨å
- å‚æ•°/è¢«è°ƒå‡½æ•°å¯ç”¨â€œçŒœæµ‹â€è¡¥è¶³ï¼ˆå·²æä¾› ParamsGuess/CallsGuessï¼‰
"""

def to_json_safely(text: str):
    text = text.strip()
    text = re.sub(r"^```[a-zA-Z]*\s*|\s*```$", "", text, flags=re.S)
    m = re.search(r"\[.*\]$", text, flags=re.S)
    if not m:
        m = re.search(r"\{.*\}", text, flags=re.S)
        if not m:
            raise ValueError("No JSON found")
        raw = f"[{m.group(0)}]"
    else:
        raw = m.group(0)
    try:
        return json.loads(raw)
    except Exception:
        raw = re.sub(r",(\s*[}\]])", r"\1", raw)
        return json.loads(raw)

def _ai_text(prompt: str) -> str:
    """
    å…¼å®¹ interlinked è¿”å›çš„å¤šç§å¯¹è±¡å½¢æ€ï¼š
    - observation.response.raw
    - observation.response
    - ç›´æ¥å­—ç¬¦ä¸²
    """
    obs = AI.ask(prompt=prompt)
    # 1) observation.response.raw
    try:
        raw = obs.response.raw  # type: ignore[attr-defined]
        if isinstance(raw, str) and raw.strip():
            return raw
    except Exception:
        pass
    # 2) observation.response
    try:
        if isinstance(obs.response, str) and obs.response.strip():  # type: ignore[attr-defined]
            return obs.response  # type: ignore[return-value]
    except Exception:
        pass
    # 3) ç›´æ¥å­—ç¬¦ä¸²
    if isinstance(obs, str):
        return obs
    # 4) å…¶å®ƒå…œåº•
    return str(getattr(obs, "response", obs))

# -------------------- ä¸»æµç¨‹ --------------------
def run(phrase: str, out_path: str, limit: int = 12, question: str = None):
    c = get_client()
    print(f"ğŸ” ç²¾ç¡®çŸ­è¯­åŒ¹é…ï¼š{phrase}")
    hits = exact_phrase_hits(c, phrase, page=200, cap=limit)
    if not hits:
        raise SystemExit("âŒ æ²¡æœ‰åŒ¹é…åˆ°åŒ…å«è¯¥çŸ­è¯­çš„å‡½æ•°/è°ƒç”¨ç‰‡æ®µã€‚æ¢ä¸ªçŸ­è¯­å†è¯•è¯•ã€‚")

    items = []
    for pl in hits:
        code = pl.get("content") or ""
        fn   = pl.get("function_name") or ""
        items.append({
            "function_name": fn,
            "file": pl.get("file"),
            "start_line": pl.get("start_line"),
            "end_line": pl.get("end_line"),
            "snippet": build_snippet_around_phrase(code, phrase, ctx_lines=2),
            "params_guess": extract_params(code, fn) if fn else [],
            "calls_guess": extract_called_functions(code, fn) if fn else [],
        })

    prompt = build_prompt(phrase, items, question)
    print("ğŸ§  è°ƒç”¨ Interlinked åˆ†æâ€¦")
    resp_text = _ai_text(prompt)
    try:
        data = to_json_safely(resp_text)
    except Exception:
        data = []
        for it in items:
            data.append({
                "function_name": it["function_name"],
                "location": f"{it['file']}:{it['start_line']}-{it['end_line']}",
                "role": resp_text[:2000],
                "parameters": it["params_guess"],
                "called_functions": it["calls_guess"],
                "logic_flow": [],
                "possible_causes": [],
                "diagnostics": [],
            })

    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²ç”Ÿæˆï¼š{out_path}")

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--phrase", "-p", required=True, help="è¦ç²¾ç¡®åŒ¹é…çš„çŸ­è¯­ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰")
    ap.add_argument("--out", "-o", default="output/phrase_analysis.json")
    ap.add_argument("--limit", "-k", type=int, default=12, help="æœ€å¤šåˆ†æçš„å‘½ä¸­æ¡ç›®æ•°")
    ap.add_argument("--q", help="å¯é€‰ï¼šé—®é¢˜åœºæ™¯ï¼ˆå¦‚ï¼šä¸ºä»€ä¹ˆä¸åæ•°æ®ï¼Ÿï¼‰")
    args = ap.parse_args()
    run(args.phrase, args.out, args.limit, args.q)
