from __future__ import annotations

import os
import re
import sys
import json
import base64
import logging
import requests
import mimetypes
from time import sleep
from datetime import datetime
from typing import Any, Optional, TYPE_CHECKING
from collections.abc import Iterator
from pydantic import BaseModel, ConfigDict

from interlinked.core.tool import Tool
from interlinked.core.config import Config
from interlinked.core.utilities import Utilities
from interlinked.core.clients.basevectorstoreclient import BaseVectorStoreClient
from interlinked.core.clients.baseaiclient import BaseAIClient, AIModel, AIClientResponse, ToolCall


# At module level - for runtime use
try:
	from endor.common.errors import EndorSDKError, APITimeoutError, AuthenticationError, UnauthorizedError

except ModuleNotFoundError:
    # Create placeholder exceptions that won't cause import errors
    # but will be properly imported when EndorClientFactory.create_client() runs
    EndorSDKError = Exception
    APITimeoutError = Exception
    AuthenticationError = Exception
    UnauthorizedError = Exception

# TYPE_CHECKING block - for type hints only
if TYPE_CHECKING:
    try:
        from endor.core.api import (AgentsApi, AnswerAccuracyApi, ChatCompletionsApi,
                                    CompletionsApi, DocumentProcessingApi, EmbeddingsApi,
                                    GuardrailsApi, IngestionsApi, ModelsApi, ProductsApi,
                                    ProjectsApi, StructuredIngestionsApi, WorkflowsApi)
    except ImportError:
        # If endor is not available during type checking, use Any
        AgentsApi = Any
        AnswerAccuracyApi = Any
        ChatCompletionsApi = Any
        CompletionsApi = Any
        DocumentProcessingApi = Any
        EmbeddingsApi = Any
        GuardrailsApi = Any
        IngestionsApi = Any
        ModelsApi = Any
        ProductsApi = Any
        ProjectsApi = Any
        StructuredIngestionsApi = Any
        WorkflowsApi = Any

logger = logging.getLogger(__name__)

class Project(BaseModel):

	# internal field
	model_config = ConfigDict(arbitrary_types_allowed=True)

	# the ID of this Project
	id: str

	# the name of this Project
	name: str

	# a list of App IDs (from idms.apple.com) that can use this Project
	app_ids: list[str]

	# a list of group DSIDs (from Apple Directory) that can view/edit/delete this Project
	group_dsids: list[str]

	# the DSID of the person/ID of the app that created this Project
	created_by: str

	# the DSID of the person/ID of the app that last updated this Project
	modified_by: Optional[str] = None

	# the datetime when this Project was created
	created_at: datetime

	# the datetime when this Project was last updated
	modified_at: Optional[datetime] = None

	# [internal]
	client: 'EndorClient' = None


class Workflow(BaseModel):
	"""
	View a list of all the fields in each key.
	[View fields â€º](https://docs.endor.apple.com/AML-Endor/endor-documentation/api-reference/#/operations/createWorkflow)
	"""

	# internal field
	model_config = ConfigDict(arbitrary_types_allowed=True)

	# the ID of this Workflow
	id: str

	# the name of this Workflow
	project_id: str

	# the type of the workflow [Allowed values: smart_answer, semantic_search, intent_route, free_prompt, lookup]
	workflow_type: Optional[str] = None

	# rag Fusion allows the system to generate answers that include multiple details, facts, or reasoning steps.
	rag_fusion: Optional[bool] = None

	# contains details of the model used for this Workflow
	language_model: Optional[dict] = None

	# contains details of the embedding model and filters
	data_retrieval: Optional[dict]

	# configuration of conversation
	conversation: Optional[dict] = None

	query_reformulation: Optional[dict] = None

	# contains whether pre-guardrails are enabled and a list of them
	pre_guardrail: Optional[dict] = None

	# contains whether post-guardrails are enabled and a list of them
	post_guardrail: Optional[dict] = None

	# the DSID of the person/ID of the app that created this Workflow
	created_by: Optional[str] = None

	# the DSID of the person/ID of the app that last updated this Workflow
	modified_by: Optional[str] = None

	# the datetime when this Workflow was created
	created_at: datetime

	# the datetime when this Workflow was last updated
	modified_at: Optional[datetime] = None

	# [internal]
	client: 'EndorClient' = None

	@property
	def project(self) -> Project:
		"""
		Returns the project for this Workflow
		"""
		return self.client.get_project(id=self.project_id)


class EndorClientFactory:
	@staticmethod
	def create_client(auth_type='OIDC_AUTO', app_id=None, app_password=None, client_id=None, client_secret=None,
	                  cert_file=None, key_file=None, oidc_token=None, base_url=None):

		if base_url is None:
			base_url = "https://api.endor.apple.com"

		try:
			from endor import Client
			from endor.common.errors import EndorSDKError, APITimeoutError, AuthenticationError, UnauthorizedError
			from endor.core.api import (AgentsApi, AnswerAccuracyApi, ChatCompletionsApi,
                                        CompletionsApi, DocumentProcessingApi, EmbeddingsApi,
                                        GuardrailsApi, IngestionsApi, ModelsApi, ProductsApi,
                                        ProjectsApi, StructuredIngestionsApi, WorkflowsApi)

			if auth_type == 'NARRATIVE':
				sdk_client = Client(platform="endor",
								configuration= {
								"auth_method": "narrative",
								"cert_file": cert_file,
								"key_file": key_file,
                                "host": base_url
								})
			elif auth_type == 'A3':
				sdk_client = Client(platform="endor",
								configuration= {
								"auth_method": "a3",
								"app_id": app_id,
								"app_password": app_password,
                                "host": base_url
								})
			elif auth_type == 'OIDC':
				sdk_client = Client(platform="endor",
								configuration= {
								"auth_method": "oidc",
								"client_id": client_id,
								"client_secret": client_secret,
			                    "host": base_url
								})
			elif auth_type == 'OIDC_MANUAL':
				sdk_client = Client(platform="endor",
								configuration= {
								"auth_method": "oidc_manual",
								"oidc_token": oidc_token,
			                    "host": base_url
								})
			elif auth_type == 'OIDC_AUTO' and Config.current.is_development: # OIDC_AUTO and in dev environment
				sdk_client = Client(platform="endor",
								configuration={
									"host": base_url
								})
			else:
				# This covers both: auth_type not in ['A3', 'OIDC', 'OIDC_AUTO', 'OIDC_MANUAL', 'NARRATIVE']
				# AND auth_type == 'OIDC_AUTO' but not in development
				raise ValueError(
					"Invalid authentication configuration for EndorClient. Please provide either:\n"
					"â€¢ A3 authentication: EndorClient(app_id=<your_app_id>, app_password=<your_password>)\n"
					"â€¢ OIDC authentication: EndorClient(client_id=<your_client_id>, client_secret=<your_secret>)\n"
					"â€¢ OIDC Manual authentication: EndorClient(oidc_token=<your_oidc_token>)\n"
					"â€¢ Narrative authentication: EndorClient(cert_file=<your_cert_file>, key_file=<your_key_file>)\n"
					f"â€¢ OIDC_AUTO is only available in development mode (current: {'development' if Config.current.is_development else 'production'})"
				)

			logger.debug('Endor SDK client initialized successfully, auth_type: %s', auth_type)
			return sdk_client

		except ModuleNotFoundError:
			from interlinked.core.utilities import Utilities
			logger.info('Installing apple-endor-sdk...')
			Utilities.install_package('apple-endor-sdk')
			return EndorClientFactory.create_client(auth_type, app_id, app_password, client_id, client_secret, cert_file, key_file, oidc_token, base_url)


class EndorClient(BaseAIClient, BaseVectorStoreClient):
	"""
	Use this client to interact with [endor.apple.com](endor.apple.com). Endor is generative AI platform for enterprise applications at Apple.

	The Endor platform offers fine-tuned large language models (LLMs) and embeddings as services, as well as pluggable guardrails.
	"""

	ROLE_USER: str = 'user'
	ROLE_TOOL: str = 'tool'
	ROLE_SYSTEM: str = 'system'
	ROLE_ASSISTANT: str = 'assistant'

	IDMS_APP_ID: int = 199323
	IDMS_APP_CONTEXT: str = 'endor'

	# how long, in seconds, this client should wait for responses
	TIMEOUT: int = 120

	# the maximum of times to retry if there are network errors
	MAX_RETRIES: int = 4

	# [Advanced] how long the A3 token should last, in milliseconds
	A3_TOKEN_EXPIRY: int = 27000000

	# your A3 app ID (from idms.apple.com)
	# set via `EndorClient(app_id=â€¦)`
	app_id: int = None

	# your A3 app password (from idms.apple.com)
	# set via `EndorClient(â€¦, app_password=â€¦)`
	app_password: str = None

	# your OIDC client ID (from idms.apple.com)
	# set via `EndorClient(client_id=â€¦)`
	client_id: int = None

	# your OIDC client secret (from idms.apple.com)
	# set via `EndorClient(â€¦, client_secret=â€¦)`
	client_secret: str = None

	# your Narrative certificate file path
	# set via `EndorClient(cert_file=â€¦)`
	cert_file: str = None

	# your Narrative private key file path
	# set via `EndorClient(key_file=â€¦)`
	key_file: str = None

	# your OIDC token for manual authentication
	# set via `EndorClient(oidc_token=â€¦)`
	oidc_token: str = None

	# Auth type - OIDC/A3/NARRATIVE/OIDC_MANUAL
	auth_type: str = None

	model_name: str = None
	options: dict[str, Any] = None
	embedding_model_name: str = None

	# [Internal] the A3 token generated when ruuning in production
	a3_token: str = None

	# [Internal] A3 token expiration time
	expiration_time: int = None

	def __init__(self, model_name: str = None, embedding_model_name: str = None,
				 app_id: int = None, app_password: str = None, client_id: str = None,
				 client_secret: str = None, cert_file: str = None, key_file: str = None,
				 oidc_token: str = None, base_url: str = None, options: dict[str, Any] = None):
		"""
		Initializes the EndorClient to use in `AI.ask(prompt='â€¦', client=EndorClient(â€¦))`

		If you haven't onboarded yet to Endor, visit [Endor Documentation](https://docs.endor.apple.com/AML-Endor/endor-documentation/docs/getting-started)

		@param model_name(str): (optional) The default model name to use to chat
		@param embedding_model_name(str): (optional) The default model name to use to embeddings
		@param app_id(int): If using A3, your A3 app ID (from idms.apple.com)
		@param app_password(str): If using A3, your A3 app password (from idms.apple.com)
		@param client_id(str): If using OIDC (needed to use the Gemini models), your client ID (from idms.apple.com)
		@param client_secret(str): If using OIDC (needed to use the Gemini models), your client secret (from idms.apple.com)
		@param cert_file(str): If using Narrative authentication, path to the certificate file (chain.pem)
		@param key_file(str): If using Narrative authentication, path to the private key file (private.pem)
		@param oidc_token(str): If using OIDC Manual authentication, your OIDC token
		@param base_url(str): (optional) If you would like to use Endor UAT
		@param options(dict): (optional) Any default options you'd like to set for the model (check with the Endor team for full list)
		"""

		# prefix `base_url` if it doesn't have `http://â€¦`
		if base_url and not base_url.startswith('http'):
			base_url = f'http://{base_url}'

		self.app_id = app_id or Config.current.IDMS_APP_ID
		self.app_password = app_password or Config.current.IDMS_APP_PASSWORD

		self.client_id = client_id or Config.current.IDMS_APP_OIDC_CLIENT_ID
		self.client_secret = client_secret or Config.current.IDMS_APP_OIDC_CLIENT_SECRET

		self.cert_file = cert_file or Config.current.NARRATIVE_CERT_FILE
		self.key_file = key_file or Config.current.NARRATIVE_KEY_FILE

		self.oidc_token = oidc_token or Config.current.ENDOR_OIDC_TOKEN

		# ensure that App ID is an integer
		self.app_id = int(self.app_id) if self.app_id else None

		# Check for auth conflicts
		if self.cert_file and self.key_file:
			if self.app_id and self.app_password:
				logger.warning('Both Narrative and A3 auth types are provided. defaulting to Narrativeâ€¦')
				self.app_id = None
				self.app_password = None
			if self.client_id and self.client_secret:
				logger.warning('Both Narrative and OIDC auth types are provided. defaulting to Narrativeâ€¦')
				self.client_id = None
				self.client_secret = None
		elif self.client_id and self.client_secret and self.app_id and self.app_password:
			logger.warning('Both A3 and OIDC auth types are provided. defaulting to A3â€¦')
			self.client_id = None
			self.client_secret = None

		# Determine authentication type
		if self.cert_file and self.key_file:
			# Use Narrative if certificate and key files are provided
			self.auth_type = 'NARRATIVE'
			logger.debug('Using Narrative authentication with cert_file: %s, key_file: %s', self.cert_file, self.key_file)

		elif self.oidc_token:
			# Use OIDC Manual if OIDC token is provided
			self.auth_type = 'OIDC_MANUAL'
			logger.debug('Using OIDC authentication with provided token, auto-refresh of token is not supported')

		elif self.app_id and self.app_password:
			# Use A3 if A3 credentials are provided
			self.auth_type = 'A3'

		elif self.client_id and self.client_secret:
			# Use OIDC with credentials if OIDC credentials are provided
			self.auth_type = 'OIDC'
		else:
			# Use auto OIDC if no credentials are provided
			self.auth_type = 'OIDC_AUTO'

		self.base_url = base_url or Config.current.ENDOR_BASE_URL
		self.model_name = model_name or 'endor-text-mixtral-8x22b-20250309'
		self.embedding_model_name = embedding_model_name or 'bge-large-en-v1.5'

		self.options = {**{

			'top_p': 1,
			'temperature': 0.6,
			'repetition_penalty': 1.0,

		}, **(options or {})}

		self.sdk_client = EndorClientFactory.create_client(self.auth_type, self.app_id, self.app_password,
		                                                  self.client_id, self.client_secret,
		                                                  self.cert_file, self.key_file, self.oidc_token, self.base_url)


	def get_models(self) -> list[AIModel]:
		"""
		Returns a list of `AIModel` containing models available
		"""
		response = self.sdk_client.models.list_models()

		if not response.models:
			logger.error('ListModels: No models found: %s', response)

		return [AIModel(name=model.model_id, description=model.description, supports_stream=model.supports_streaming, raw=model) for model in response.models]

	@Utilities.dynamic
	def get_response(self, messages: str|list[dict], tools: list[dict[str, Any]] = None, model_name: str = None,
					 temperature: float = None, stream: bool = False, format_: str = None, _retry_count: int = 0,
					 **kwargs) -> AIClientResponse | Iterator[AIClientResponse]:
		"""
		Returns chat response for a given messages.
		It is recommended to use `AI.ask(â€¦, client=OllamaClient(model_name=â€¦))` instead of using this API directly.

		@param messages(str|list): A list of messages or a prompt string (which gets converted to a message)
		@param tools(list): (Optional) A list of functions/tools to give AI access to
		@param model_name(str): (Optional) The name of the model to use. Defaults to the model you use in `AI.ask(â€¦)`
		@param temperature(float): (Optional) The temperature (controls creativeness). Defaults to the value in `AI.ask(â€¦)`,
								   which is typically 0.6
		@return (tuple): a response
		"""

		if not model_name:
			model_name = self.model_name

		messages = messages if isinstance(messages, list) else [self.create_message(role=self.ROLE_USER, content=messages)]

		options: dict[str, Any] = self.options.copy()

		if temperature is not None:
			options['temperature'] = temperature

		if stream:
			return self.get_response_stream(messages=messages, model_name=model_name, options=options, format_=format_, **kwargs)

		if tools:
			tool_config = {'tools': [tool.to_dict(client=self) for tool in tools]}
			kwargs = {
				'model_id': model_name,
				'messages': messages,
				'generation_config': options,
				'tool_config': tool_config
			}
		else:
			kwargs = {
				'model_id': model_name,
				'messages': messages,
				'generation_config': options
			}

		for retry_attempt in range(self.MAX_RETRIES + 1):
			try:
				response = self.sdk_client.chat_completions.generate_chat_completions(**kwargs)
				break  # Success - exit retry loop
			except (APITimeoutError, AuthenticationError, UnauthorizedError) as exception:
				if retry_attempt < self.MAX_RETRIES:
					logger.warning('request timed out. trying againâ€¦')
					sleep(retry_attempt + 5)
					continue
				else:
					logger.error('request timed out too many times')
					raise exception

		if not response.choices or not response.choices[0] or not response.choices[0].message:
			logger.error('GenerateChatCompletions: No response found: %s', response)

		choice = response.choices[0]
		message = choice.message
		response_dict = response.to_dict() if response else None

		# Handle the case where message is None
		if not message:
			finish_reason = choice.finish_reason
			logger.warning(
				f'GenerateChatCompletions: Empty message received. Finish reason: {finish_reason}')

			if finish_reason == 'length':
				# Response was cut off due to length limits
				raise Exception(
					f"Response was truncated due to length limits. For Gemini 2.5 models, if the reasoning uses up all the max_tokens limit, the response will be empty.\n"
					f"ðŸ’¡ Try increasing max_tokens in generation_config.\n"
					f"ðŸ’¡ Max_tokens limit is 65535 for Endor Gemini 2.5 models\n"
					f"Response: {response}"
				)
			else:
				# Other reasons for empty message
				raise Exception(
					f"Empty response received from model '{model_name}'.\n"
					f"Finish reason: {finish_reason}\n"
					f"Response: {response}"
				)

		ai_client_response: AIClientResponse = self.get_ai_client_response_for_message(message=message.to_dict())
		ai_client_response.metadata = {key: value for key, value in response_dict.items() if key != 'choices'}

		return ai_client_response

	def get_response_stream(self, messages: list[str], model_name: str, _retry_count: int = 0, **kwargs) -> Iterator[AIClientResponse]:
		"""
		[Internal]
		To use streaming, please use `AI.ask(â€¦, stream=True)` or `EndorClient().get_response(â€¦, stream=True)`

		Calls EndorClient's /api/chat endpoint and returns raw JSON response
		@param messages(list[str]): The messages to send.
		@param model_name(str): The name of the model to use.
		@param format_(str): The format of the response (optional).
		@param _retry_count(int): The retry count (internal use).
		@return (Iterator[AIClientResponse]): An iterator of AIClientResponse objects.
		"""

		options: dict[str, Any] = self.options.copy()

		# default max tokens
		if 'max_tokens' not in options:
			options['max_tokens'] = 400

		generator = self.sdk_client.chat_completions.generate_chat_completions_stream(
            model_id=model_name,
            messages=messages,
            generation_config=options
        )

		token_count = 0
        # GenerateChatCompletionsStreamResponse
		for stream_response_obj in generator:

			try:

				# 1. Validate 'choices' attribute
				if not hasattr(stream_response_obj, 'choices') \
					or not stream_response_obj.choices:

					logger.debug('Stream response object has no \'choices\' or \'choices'' is empty: %s', stream_response_obj)
					continue

				            # 2. Get the first choice object  - only one choice is supported currently
				choice_obj = stream_response_obj.choices[0]

				            # 3. Validate 'delta' attribute on the choice object
				if not hasattr(choice_obj, 'delta') \
					or choice_obj.delta is None:

					logger.debug('Choice object has no \'delta\' or \'delta\' is None: %s', choice_obj)
					continue


				            # 4. Get the delta model
				delta_model = choice_obj.delta

				            # 5. Convert the delta Pydantic model to a dictionary
				delta_dict: dict[str, Any]
				if hasattr(delta_model, 'model_dump') and callable(delta_model.model_dump):
					delta_dict = delta_model.model_dump(exclude_none=True)
				elif hasattr(delta_model, 'dict') and callable(delta_model.dict): # Fallback for Pydantic v1
					delta_dict = delta_model.dict(exclude_none=True)
				elif isinstance(delta_model, dict): # Should be rare - just to be safe
					delta_dict = delta_model
				else:

					logger.warning('Delta object: %s is not a recognized Pydantic model or dict. Skipping. Object: %s',
				                               type(delta_model), delta_model)
					continue

				            # 6. Check if the resulting delta_dict is empty (e.g., if delta_model had all None fields)
				if not delta_dict:

					logger.debug('Delta dictionary is empty after conversion (all fields might have been None). Skipping.')
					continue



                # 7. Process the delta_dict using your existing method
				result: AIClientResponse = self.get_ai_client_stream_response_for_message(message=delta_dict)

                # 8. Update token count
				# also filter out <think>REASONING CONTENT</think>, otherwise won't generate outputs
				if result.content is not None and not re.match(r"<think>(.*)</think>", result.content, re.DOTALL):
					token_count += len(result.content)

                # 9. Yield the AIClientResponse
				yield result

                # 10. Check max_tokens limit to handle case where Endor models would stream forever sometimes
				current_max_tokens = options.get('max_tokens', 400)
				if token_count >= current_max_tokens:
					logger.debug('Max tokens (%s) reached or exceeded based on content length. Stopping stream', current_max_tokens)
					break
			except StopIteration:

			    # This exception is raised when the generator is exhausted.
				logger.debug('Stream generator exhausted (StopIteration)')
				break # Exit the loop cleanly

			except AttributeError as attribute_error:

				logger.warning('AttributeError while processing stream object (check SDK model structure): %s. Object: %s',
			                            attribute_error, stream_response_obj)
				continue # Skip this problematic chunk

			except IndexError as index_error: # More specific than general Exception for list index issues

				logger.warning('IndexError while processing stream object (likely \'choices\' list): %s. Object: %s',
			                            index_error, stream_response_obj)
				continue

			except Exception as general_exception:

				# Catch any other unexpected errors for a specific chunk
				logger.error('Unexpected error processing a stream chunk: %s. Object: %s',
			                          general_exception, stream_response_obj, exc_info=True)
				continue # Attempt to continue with the next chunk



	def get_completion(self, prompt: str, model_name: str = None,
					   temperature: float = None, **kwargs) -> AIClientResponse:
		"""
		Returns a completion for a given text/code

		@param prompt(str): a text prompt/code to complete
		@param model_name(str): the name of the model to use
		@param temperature(float): the temperature to use (creativeness)
		@return (AIClientResponse): a response (the completion will be in `.content`)
		"""

		if not model_name:
			model_name = self.model_name

		options: dict[str, Any] = self.options.copy()

		if temperature is not None:
			options['temperature'] = temperature

		response = self.sdk_client.completions.generate_completions(
            model_id=model_name,
            prompt=prompt,
            generation_config=options
        )

		response_dict: dict[str, Any] = response.to_dict()
		completions: list[dict] = response_dict.get('completions', [])

		if not completions or not completions[0].get('text'):
			logger.error('GenerateCompletions: No completion found: %s', response_dict)

		return AIClientResponse(raw=response_dict, content=completions[0].get('text'))

	def get_embedding(self, input: str, model_name: str = None, _retry_count: int = 0) -> list[float]:
		"""
		Returns embeddings for a given input string

		@param input(str): The text input to get an embedding for
		@param model_name(str):
		"""

		if not model_name:
			model_name = self.embedding_model_name

		if isinstance(input, str):
			input = [input]

		for retry_attempt in range(self.MAX_RETRIES + 1):
			try:
				response = self.sdk_client.embeddings.generate_embeddings(
                            model_id=model_name,
                            input=input
                        )
				break  # Success - exit retry loop
			except requests.exceptions.ReadTimeout as exception:
				if retry_attempt < self.MAX_RETRIES:
					sleep(retry_attempt + 5)
					continue
				else:
					logger.error('GenerateEmbeddings: Request timed out too many times')
					raise exception


		if not response.data or not response.data[0].embedding:
			logger.error('GenerateEmbeddings: No data found: %s', response)

		return response.data[0].embedding

	""" Utilities """

	def get_message_for_tools(self, tools: list[Tool]) -> dict[str, Any]:
		"""
		Returns a system message for a given list of tools
		"""

		tools: str = '\n'.join([json.dumps(tool.to_dict(self), indent=4) for tool in tools])
		message: dict[str, Any] = self.create_message(role=self.ROLE_SYSTEM, content=f'{TOOLS_SYSTEM_PROMPT}\n{tools}')
		return message

	def create_message(self, role: str, content: str, files: list[str|bytes] = None, **kwargs) -> dict[str, Any]:
		"""
		Creates a message that matches the format used by Endor

		@param role(str): the value of any of the `ROLE_` properties
		@param content(str): the text content of the message
		@param files(list): a list of file paths or bytes
		"""

		message: dict[str, Any] = {'role': role, 'contents': []}

		if files:

			for file in files:

				data: str = None

				if isinstance(file, str):

					# local file
					if file.startswith(('/', '~', '.')) or os.path.exists(file):
						data = self.encode_file(path=file)

					# for files hosted somewhere else, pass the string as is
					else:
						data = file

				else:
					data = self.encode_bytes(bytes_=file)

				mime_type, _ = mimetypes.guess_type(file)

				message['contents'].append(
					{
						"inline_data": {
							'data': data,
							'mime_type': mime_type
						}
					}
				)

		# if this is a message from a tool/function, add the tool arguments
		if role == self.ROLE_TOOL:
			message['contents'].append(
                {
                    'tool_result': {
                        'name': kwargs['name'],
                        'tool_call_id': kwargs['tool_call_id'],
                        'content': content
                    }
                }
			)
		else:
			message['contents'].append({'text': content})
		return message

	def get_ai_client_response_for_message(self, message: dict[str, Any]) -> AIClientResponse:
		"""
		Converts a raw response message to `AIClientResponse`

		@param message(dict): e.g. `{'role': 'user', 'content': 'Lorem ipsum'}`
		@return (AIClientResponse): a response
		"""

		# temporary workaround to an issue where responses from the API have an inconsistent
		# format with the expected request format
		if 'contents' not in message:

			text_content = message.get('text')
			tool_calls = message.get('tool_calls')
			role = message.get('role')

			# Create contents array with proper structure for Gemini
			contents = []

			if role == 'assistant' and tool_calls:

				# For assistant messages with tool calls, convert to tool_use format
				for tool_call in tool_calls:

					contents.append({
						'tool_use': {
							'id': tool_call['id'],
							'type': 'function',
							'function': {
								'name': tool_call['function']['name'],
								'arguments': tool_call['function']['arguments']
							}
						}
					})
				# Add text content if present
				if text_content:
					contents.append({'text': text_content})
			else:
				# For regular messages, just add text content
				contents.append({'text': text_content or ''})

			# Preserve other fields (except text and tool_calls which we handled)
			preserved_fields = {field_name: field_value for field_name, field_value in message.items() if field_name not in ['text', 'tool_calls']}
			message = {**preserved_fields, 'contents': contents}

		content: str = ''

		if contents := message.get('contents', []):
			content = contents[0].get('text', '')

		# Extract tool_calls from message (could be at message level or inside contents)
		raw_tool_calls = message.get('tool_calls', [])

		if not raw_tool_calls and 'contents' in message:

			# Check if tool_calls are inside contents array as 'tool_use' format
			for content_item in message.get('contents', []):

				if 'tool_use' in content_item:

					# Convert tool_use back to tool_calls format for ToolCall creation
					tool_use = content_item['tool_use']
					raw_tool_calls.append({
						'id': tool_use['id'],
						'type': tool_use.get('type', 'function'),
						'function': {
							'name': tool_use['function']['name'],
							'arguments': tool_use['function']['arguments']
						}
					})

		tool_calls: list[ToolCall] = [ToolCall(id=raw_tool_call.get('id'), name=raw_tool_call.get('function', {}).get('name'),
									   raw_arguments=raw_tool_call.get('function', {}).get('arguments')) for raw_tool_call in raw_tool_calls]

		return AIClientResponse(raw=message, content=content, tool_calls=tool_calls)

	def get_ai_client_stream_response_for_message(self, message: dict[str, Any]) -> AIClientResponse:
		"""
		Converts a raw stream response message to `AIClientResponse`
		@param message(dict[str, Any]): e.g. `{'role': 'user', 'content': 'Lorem ipsum'}`
		@return (AIClientResponse): a response
		"""


		if 'contents' not in message:

			message = {**message, 'contents': [{'text': message.get('content')}]}
			message.pop('text', None)
			message.pop('content', None)

		content: str = ''

		if contents := message.get('contents', []):
			content = contents[0].get('text')

		if content and content.endswith('[DONE]'):
			content = content[:-len('[DONE]')]

		# deepseek model would respond with 'reasoning_content' when content is None
		if not content and 'reasoning_content' in message:
			content = f"<think>{message['reasoning_content']}</think>"

		return AIClientResponse(raw=message, content=content, tool_calls=[])

	def append_message(self, message: dict[str, Any], messages: list[dict]) -> None:
		"""
		[Internal]
		Merges subsequent tool responses into one message to
		match Endor API's conversation schema requirements

		This prevents "ValidationException: The number of toolResult blocks
		at messages.X.content exceeds the number of toolUse blocks of previous turn"
		errors when tools make nested AI.ask() calls.
		"""
		if message.get('role') == self.ROLE_TOOL and \
			messages and messages[-1].get('role') == self.ROLE_TOOL:
			# Merge tool result into previous tool message
			messages[-1]['contents'].extend(message['contents'])
			return

		messages.append(message)

	""" Endor-specific APIs: Guardrails """

	def get_guards(self) -> list[dict]:
		"""
		Returns a list of available guards/guardrails, such as PII redaction

		@return (list): a list of guards/guardrails
		"""

		response = self.sdk_client.guardrails.list_guards()
        # Check if response.guards is not empty - logger error if it is empty
		if not response.guards:

			logger.error('No guards found, response: %s', response)


        # following same response format as in original client
		return response.to_dict()

	def get_guard_response(self, id: str, content: str|dict, parameters: dict[str, Any]) -> dict:
		"""
		Runs a Guard and returns its response/results

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		response: dict = endor_client.get_guard_response(id='gd-profanity-check-v1',
														 content='Some profanity here',
														 parameters={'threshold': 0.5})
		print(response.get('text'))
		# Some ****** here
		```

		@param id(str): the id of the guard (from `get_guards(â€¦)`)
		@param content(str|dict): the text content of the prompt to apply the guard to
		@param parameters(dict): a dictionary of parameters specific to the guard
		@return (dict): a dictionary response with the guard's response/results
		"""

		if isinstance(content, str):
			content = {'text': content}

		response = self.sdk_client.guardrails.execute_guard(
            guard_id=id, content=content, parameters=parameters)

		if response.error:
			logger.error('Error executing guard_id: %s, error: %s', id, response.error)

		return response.to_dict()

	""" Endor-specific APIs: Document Processing """

	def split_document(self, id: str, data: bytes) -> dict:
		"""
		Splits a given document into multiple chunks. Currently, only supports PDFs

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')

		with open('data/file.pdf', 'rb') as file:

			output: dict = endor_client.split_document(id='file.pdf', data=file.read())
			print(output.get('output'))
			# {'numberOfPages': 4, 'output': {'1': 'â€¦'}}
		```

		@param id(str): The ID (file name) of the document (e.g. `file.pdf`)
		@param data(bytes): The contents of the file
		@return (dict): The raw response from the API
		"""

		response = self.sdk_client.document_processing.pdf2pages_content(
            document_id=id,
            data=base64.b64encode(data).decode()
        )

		if response.status.lower() != 'success':
			logger.error('Error splitting document, response: %s', response)

		response_json: dict[str, Any] = response.to_dict()
		return response_json

	def parse_content(self, id: str, data: bytes, file_type: str, parser_name: str = None,
					  page_count: int = None, page_number: int = None) -> dict:
		"""
		Parses a given content/file, then returns the parsed results

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')

		with open('data/file.pdf', 'rb') as file:

			output: dict = endor_client.parse_content(id='file.pdf', data=file.read(), file_type='application/pdf')
			print(output.get('output'))
			# {'â€¦': 'â€¦'}
		```

		@param id(str): The ID (file name) of the document (e.g. `file.pdf`)
		@param data(bytes): The contents of the file
		@param parser_name(str): (Optional) One of the available parsers (e.g. `PDF`, `DOCAI`, and `TEXTRACT`)
		@param page_count(int): (Optional) Number of pages in document if this needs to be added in parser output
		@param page_number(int): (Optional) Page number in case of processing pdf document, since pdf is processed per page
		@return (dict): The raw response from the API
		"""

		optional_args = {}
		if parser_name is not None:
			optional_args['document_parser'] = parser_name
		if page_count is not None:
			optional_args['number_of_pages'] = page_count
		if page_number is not None:
			optional_args['page_num'] = page_number

		response = self.sdk_client.document_processing.parse_content(
            document_id=id,
            data=base64.b64encode(data).decode(),
            file_type=file_type,
            **optional_args
        )
		response_json: dict[str, Any] = response.to_dict()

		return response_json

	def get_chunked_content(self, id: str, structures: list[dict], file_type: str, page_count: int = None,
							page_number: int = None, chunk_size: int = None, chunk_type: str = 'SMALL',
							chunk_overlap: int = 20, chunker_type: str = 'FIXED_CONTEXT') -> dict:
		"""
		Chunks a given content/file, then returns the chunked version

		**How to use**
		```python

		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		structures = [
            {
                "index": 0,
                "type": "Paragraph",
                "content": "Sample Text Content",
                "bbox": [110, 200, 300, 400],
                "confidence": 97,
                "elementId": "UUID"
            }
        ]
		response = endor_client.get_chunked_content(id='file.pdf', structures=structures, file_type='application/pdf')
		print(response.get('output'))
			# {'â€¦': 'â€¦'}
		```

		@param id(str): The ID (file name) of the document (e.g. `file.pdf`)
		@param structures(list): The structures of the content to parse ([Learn Moreâ€¦](https://docs.endor.apple.com/AML-Endor/endor-documentation/api-reference/#/operations/chunkContent))
		@param file_type(str): The mine type of the file (e.g. `application/pdf`)
		@param page_count(int): (Optional) Number of pages in document if this needs to be added in parser output
		@param page_number(int): (Optional) Page number in case of processing pdf document, since pdf is processed per page
		@param chunk_size(int): (Optional) Chunk size limit in characters
		@param chunk_type(int): (Optional) Chunk size limit in characters. LARGE (1500) or SMALL (700), overridden by `chunk_size`
		@param chunk_overlap(int): (Optional) Number of characters to overlap between chunks (in percentage)
		@param chunker_type(str): (Optional) Selection of chunker. `RECURSIVE` or `FIXED_CONTEXT` (in-house). Note `RECURSIVE` chunker is only supported for text files (`text/plain`)
		@return (dict): The raw response from the API
		"""

		response = self.sdk_client.document_processing.chunk_content(
			document_id=id,
			file_type=file_type,
			structures=structures,
			document_chunker=chunker_type,
			total_pages=page_count,
			page_num=page_number,
			chunk_size=chunk_size,
			chunk_overlap=chunk_overlap,
			chunk_type=chunk_type
		)

		if response.status.lower() != 'success':
			logger.error("Error chunking document, response: %s", response)

		return response.to_dict()

	""" Endor-specific APIs: Projects """

	def create_project(self, name: str, group_dsids: list[int], app_ids: list[int] = None) -> Project:
		"""
		Creates a Project. Projects in Endor control RBAC, embedding model configurations, etc.

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient, Project

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		project: Project = endor_client.create_project(name='my-project', group_dsids=[9531874])
		print(project.id)
		# d0255948-c49e-â€¦
		```

		@param name(str): The name of the new Project you'd like to create
		@param group_dsids(list): (Optional) A list of group DSIDs (from Apple Directory) that can view/edit/delete this Project
		@param app_ids(list): (Optional) The additional IDs of apps (from idms.apple.com) that use this Project
		@return (Project): The new Project
		"""

		app_ids = [str(app_id) for app_id in app_ids] if app_ids else []
		group_dsids = [str(group_dsid) for group_dsid in group_dsids] if group_dsids else []

		# add our own App ID (if set)
		if self.app_id and self.app_id not in app_ids:
			app_ids.append(str(self.app_id))

		response = self.sdk_client.projects.create_project(
			name=name,
			app_ids=app_ids,
			ds_groups=group_dsids
		)

		if not response.project_id:
			logger.error('Error creating project, response: %s', response)

		response_json: dict[str, Any] = response.to_dict()
		response_json['id'] = response_json.pop('project_id')
		response_json['group_dsids'] = response_json.pop('ds_groups')
		response_json['modified_at'] = response_json.pop('updated_at', None)
		response_json['modified_by'] = response_json.pop('updated_by', None)

		return Project(**response_json, client=self)

	def get_projects(self) -> list[Project]:
		"""
		Returns all Projects

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient, Project

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		projects: list[Project] = endor_client.get_projects()
		print(projects)
		# [Project(â€¦), Project(â€¦), â€¦]
		```

		@return (list): A list of all available Projects
		"""

		response = self.sdk_client.projects.get_all_project()
		response_json: list[dict[str, Any]] = [project.to_dict() for project in response]

		projects: list[Project] = []

		for raw_project in response_json:
			raw_project['id'] = raw_project.pop('project_id')
			raw_project['name'] = raw_project.pop('name')
			raw_project['app_ids'] = raw_project.pop('app_ids')
			raw_project['created_by'] = raw_project.pop('created_by')
			raw_project['created_at'] = raw_project.pop('created_at')
			raw_project['modified_at'] = raw_project.pop('updated_at', None)
			raw_project['modified_by'] = raw_project.pop('updated_by', None)
			raw_project['group_dsids'] = raw_project.pop('ds_groups')
			projects.append(Project(**raw_project, client=self))

		return projects

	def get_project(self, id: str) -> Project:
		"""
		Returns a Project

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient, Project

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		project: Project = endor_client.get_project(id='d0255948-c49e-â€¦')
		print(project.name)
		# my-project
		```

		@param id(str): The ID of the project (from `.create_project(â€¦).id`)
		@return (Project): The Project
		"""

		response = self.sdk_client.projects.get_project(project_id=id)

		if not response.project_id:
			logger.error('Error getting project, response: %s', response)


		response_json: dict[str, Any] = response.to_dict()
		response_json['id'] = response_json.pop('project_id')
		response_json['group_dsids'] = response_json.pop('ds_groups')
		response_json['modified_at'] = response_json.pop('updated_at', None)
		response_json['modified_by'] = response_json.pop('updated_by', None)

		return Project(**response_json, client=self)

	def delete_project(self, id: str) -> None:
		"""
		Deletes a Project

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		EndorClient(app_id='â€¦', app_password='â€¦').delete_project(id='d0255948-c49e-â€¦')
		```

		@param id(str): The ID of the Project (e.g. `d0255948-c49e-â€¦`)
		"""

		# SDK handles any errors other than response: 204. The body is empty in the response.
		response = self.sdk_client.projects.delete_project(project_id=id)

	""" Endor-specific APIs: Ingestions """

	def ingest_documents(self, project_id: str, data: dict) -> list:
		"""
		Documents Ingestion

		For a list of supported data types, please see [Ingesting Your Data](https://docs.endor.apple.com/AML-Endor/endor-documentation/docs/guide-to-endor/ingesting-data/) in the Endor documentation.

		To allow Endor reading from your box folder, you will need to share it with `AutomationUser_2169123_798KBmmUk1@boxdevedition.com` email ID.

		For tracking updates and deletes, grant â€œEditâ€ access to the same account.

		This account is used by Endor to retrieve contents of box folder.

		If you plan to  schedule an Ingestion, please use cron expression as per example below :
		example: 0 */30 * * * * is scheduled every thirty minutes, 0 15 9-17 * * MON-FRI is scheduled to run 15 minutes past each hour but only during weekdays 9-to-5 UTC timezone. Spring CRON usage reference:https://docs.spring.io/spring-framework/reference/integration/scheduling.html.

		A minimum gap of 30 minutes is required between scheduled execution times of cron jobs.

		Cron expressions can be specified at the root level, source level, and/or link level. If a cron expression is not provided at a specific level, it will inherit the value from its parent level. The precedence is given to the expression specified at the most specific (lowest) level.

		@param project_id(str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@param request_body(dict): The request body
		@return (list): A list of IngestionStatusResponse objects
		"""

		request = data.get('request')

		# Build kwargs with only the parameters that are present in the data dictionary
		kwargs = {}

		if 'scheduled_run_time' in data:
			kwargs['scheduled_run_time'] = data['scheduled_run_time']

		if 'chunk_config' in data:
			kwargs['chunk_config'] = data['chunk_config']

		if 'parse_config' in data:
			kwargs['parse_config'] = data['parse_config']

		# If 'request' isn't explicitly specified but there are source details in the root,
    	# construct it from the data itself (backwards compatibility)
		if request is None and ('source_type' in data or 'source_details' in data):
			# Create a request object from the root level data
			request = [
				{
					key: value for key, value in data.items()
					if key not in ['scheduled_run_time', 'chunk_config', 'parse_config']
				}
			]

		response = self.sdk_client.ingestions.ingestion(project_id=project_id,
														request=request,
														**kwargs)
		# Handle the response properly
		if not response or not isinstance(response, list):
			logger.warning("Ingestion response is None")
			return response

		result = []
		for item in response:
			item_dict = {}
			# Manual conversion to ensure enum values are properly serialized
			if hasattr(item, 'dataset_id'):
				item_dict['dataset_id'] = item.dataset_id
			if hasattr(item, 'run_id'):
				item_dict['run_id'] = item.run_id
			if hasattr(item, 'run_type'):
                # Extract string value from enum
				item_dict['run_type'] = item.run_type.value if hasattr(item.run_type, 'value') else item.run_type
			if hasattr(item, 'run_status'):
                # Extract string value from enum
				item_dict['run_status'] = item.run_status.value if hasattr(item.run_status, 'value') else item.run_status
			if hasattr(item, 'link'):
				item_dict['link'] = item.link
			if hasattr(item, 'error_info'):
				item_dict['error_info'] = item.error_info
			if hasattr(item, 'request_status'):
				item_dict['request_status'] = item.request_status or []
			result.append(item_dict)
		return result

	def delete_ingested_documents(self, project_id: str, criteria: dict) -> dict:
		"""
		Delete Ingested documents using their IDs(s), a given time window, and more

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		response: dict = endor_client.delete_ingested_documents(project_id='d6476ce3-8ac7-477c-b7f4-01e4218c0321',
																criteria={'document_ids': ['1548020786384-box-63cd9685-e15f-4ef8-8439-d395fa8ea2f6']})
		```

		@param project_id (str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@param delete_config (dict): The criteria to delete. View all keys [here](https://docs.endor.apple.com/AML-Endor/endor-documentation/api-reference/#/operations/deleteDocuments).
		@return (dict): The raw delete response
		"""

		kwargs = {}
		if 'tags' in criteria:
			kwargs['tags'] = criteria['tags']

		if 'document_ids' in criteria:
			kwargs['document_ids'] = criteria['document_ids']

		if 'source_type' in criteria:
			kwargs['source_type'] = criteria['source_type']

		if 'source_links' in criteria:
			kwargs['source_links'] = criteria['source_links']

		if 'dataset_ids' in criteria:
			kwargs['dataset_ids'] = criteria['dataset_ids']

		if 'status' in criteria:
			kwargs['status'] = criteria['status']

		if 'start_run_epoch' in criteria:
			kwargs['start_run_epoch'] = criteria['start_run_epoch']

		if 'last_run_epoch' in criteria:
			kwargs['last_run_epoch'] = criteria['last_run_epoch']

		if 'start_timestamp' in criteria:
			kwargs['start_timestamp'] = criteria['start_timestamp']

		if 'last_timestamp' in criteria:
			kwargs['last_timestamp'] = criteria['last_timestamp']

		response = self.sdk_client.ingestions.delete_documents(project_id, **kwargs)

		# For certain criteria like deletion using dataset_ids, the response is empty
		if not response:
			logger.debug('No response received for delete_documents')
			return {}

		return response.to_dict()

	def reingest_documents(self, project_id: str, dataset_id: str) -> dict:
		"""
		Re-ingest documents using a data set ID

		This API will:
		1. Call the Box API to retrieve a list of files associated with the dataset-id
		2. Delete those files / data from Solr
		3. Begin the new ingestion process for the retrieved files.

		If there is any pending /ingest or /reingest request which is still in progress,
		that will be marked as 'cancelled' before starting the new ingestion process.

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		response: dict = endor_client.reingest_documents(project_id='d6476ce3-8ac7-477c-b7f4-01e4218c0321',
														 dataset_id='7be0a50a-1d0e-4493-94fd-7b7cf07817de')
		print(response.get('run_id'))
		# 1724454232242
		```

		@param project_id(str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@param dataset_id(str): The ID of the dataset (e.g. `7be0a50a-1d0e-â€¦`)
		@return (dict): A dictionary containing the ingestion status information
		"""

		response = self.sdk_client.ingestions.reingest_documents(project_id, dataset_id)

		if not response:
			logger.warning('No response received for reingest_documents')
			return {}

		# Convert the list of IngestionStatusResponse objects to a list of dictionaries
		response_json = [item.to_dict() for item in response]

		return response_json

	def get_dataset_ids(self, project_id: str) -> list[str]:
		"""
		Returns the list of all the datasets for a Project

		@param project_id(str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@return (list): A list of dataset IDs
		"""

		response = self.sdk_client.ingestions.get_all_datasets(project_id)

		if not response:
			logger.warning('No response received for get_all_datasets')

		return response

	def get_run_ids(self, project_id: str, dataset_id: str, link: str = None) -> list[str]:
		"""
		Returns the list of all the run_ids for a given dataset

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		run_ids: list[str] = endor_client.get_run_ids(project_id='d6476ce3-8ac7-â€¦', dataset_id='7be0a50a-1d0e-â€¦')
		print(run_ids)
		# [â€¦, â€¦]
		```

		@param project_id(str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@param dataset_id(str): The ID of the dataset (e.g. `7be0a50a-1d0e-â€¦`)
		@param link(str): (Optional) The source link (e.g. `https://apple.ent.box.com/folder/261549951646`)
		@return (list): A list of run IDs
		"""

		response = self.sdk_client.ingestions.get_all_run_ids_post(project_id, dataset_id, link)

		if not response:
			logger.warning('No response received for get_all_run_ids_post')
			return []

		return response

	def get_ingestion_status(self, project_id: str, dataset_id: str = None, criteria: dict = None) -> dict:
		"""
		Returns the ingestion status of all the documents for a project

		@param project_id(str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@param dataset_id(str): (Optional) The ID of a dataset (e.g. `7be0a50a-1d0e-â€¦`)
		@param criteria(dict): Criteria for getting the status of ingestion ([Learn moreâ€¦](https://docs.endor.apple.com/AML-Endor/endor-documentation/api-reference/#/operations/ingestionDatasetStatusPost))
		@return (dict): A list of statuses for a given dataset
		"""

		criteria = criteria or {}

		if dataset_id: # Unstructured Ingestion
			response = self.sdk_client.ingestions.ingestion_dataset_status_post(
				project_id=project_id, dataset_id=dataset_id, **criteria)
		else: # Structured Ingestion
			response = self.sdk_client.structured_ingestions.check_structured_ingestion_status(
				project_id=project_id, **criteria)

		response_json = [item.to_dict() for item in response]

		return response_json

	""" Endor-specific APIs: Structured Ingestions """

	def create_ingestion_schema(self, project_id: str, type: str, tags: dict[str, Any] = None,
								embedding_config: dict[str, Any] = None, chunk_config: dict[str, Any] = None) -> str:
		"""
		Creates a Structured Ingestion schema


		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		ingestion_schema_id: str = endor_client.create_ingestion_schema(project_id='d6476ce3-8ac7-â€¦', type='text')
		print(ingestion_schema_id)
		# 'e136c01'
		```

		@param project_id(str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@param ingestion_config(dict): The ingestion configuration ([Learn moreâ€¦](https://docs.endor.apple.com/AML-Endor/endor-documentation/api-reference/#/operations/ingestStructuredConfigureSchemaPost))
		@return (str): The schema ID
		"""

		response = self.sdk_client.structured_ingestions.ingest_structured_configure_schema_post(
			project_id=project_id, type=type, tags=tags, embedding_config=embedding_config, chunk_config=chunk_config)

		if not response or not response.ingestion_config_id:
			logger.warning('No response received for create_ingestion_schema')
			return None

		return response.ingestion_config_id

	def get_ingestion_schemas(self, project_id: str) -> list[dict]:
		"""
		Returns a list of Ingestion Schemas for a given project ID

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		ingestion_schemas: list[dict] = endor_client.get_ingestion_schemas(project_id='d6476ce3-8ac7-â€¦')
		print(ingestion_schemas)
		# [{'ingestion_config_id': 'â€¦', 'project_id': 'â€¦', 'type': 'â€¦', â€¦}, â€¦]
		```

		@param project_id(str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@return (list): A list of ingestion schema configurations
		"""

		response = self.sdk_client.structured_ingestions.ingest_structured_configure_schema_get(project_id=project_id)

		if not response:
			logger.warning('No response received for get_ingestion_schemas')
			return []

		response_json = [item.to_dict() for item in response]
		return response_json

	def ingest_data(self, project_id: str, ingestion_config_id: str, data: str | dict) -> dict:
		"""
		Ingests Structured Data (text or JSON)

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		response: dict = endor_client.ingest_data(project_id='d6476ce3-8ac7-â€¦', ingestion_config_id='â€¦',
												  data='the contents of a text document')
		print(response)
		# {'id': 'â€¦', 'statusMessage': 'â€¦'}
		```

		@param project_id(str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@param ingestion_config_id (str): The ID of the ingestion config
		@param data(str|dict): Plain text or JSON
		@return (dict): The raw response from the API
		"""

		if isinstance(data, str):
			body = data
			_content_type = 'text/plain'
		elif isinstance(data, dict):
			body = json.dumps(data)
			_content_type = 'application/json'
		else:
			raise Exception('The `data=` argument must be either a string or a dictionary.')

		response = self.sdk_client.structured_ingestions.ingest_structured(project_id=project_id, ingestion_config_id=ingestion_config_id, body=body, content_type=_content_type)

		if not response:
			logger.warning('No response received for ingest_data')
			return None

		return response.to_dict()

	def delete_ingestion(self, project_id: str, criteria: dict) -> list:
		"""
		Deletes structured data for a given Project ID, based on request IDs, tags, and timestamp filters

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')

		# delete by request ID
		response: list = endor_client.delete_ingestion(project_id='d6476ce3-8ac7-477c-b7f4-01e4218c0321',
													   criteria={'request_ids': ['req123']}
		)

		# delete by tags
		response: list = endor_client.delete_ingestion(project_id='d6476ce3-8ac7-477c-b7f4-01e4218c0321',
													   criteria={'tags': {'key1': 'value1', 'key2': 'value2'}})

		# delete by filters
		response: list = endor_client.delete_ingestion(project_id='d6476ce3-8ac7-477c-b7f4-01e4218c0321',
													   criteria={
															'request_ids': ['req123', 'req456'],
															'tags': {'key1': 'value1', 'key2': 'value2'},
															'created_on_epoc_range': '1719891288 TO current',
															'ingestion_on_epoc_range': '1719891288 TO 1719891288'
														})
		```

		@param project_id (str): The ID of the Project (e.g. `d6476ce3-8ac7-â€¦`)
		@param criteria (dict): The criteria for deleting ingestions. Can include `request_ids`, `tags`,
							   `created_on_epoc_range`, and `ingestion_on_epoc_range`.
		@return (list): A list of `dict`s, each containing the `request_id` and the `status` (Deleted/Failed) of the delete operation.
		"""

		response = self.sdk_client.structured_ingestions.delete_ingestion(
			project_id=project_id, **criteria
		)

		if not response:
			logger.warning('No response received for delete_ingestion')
			return []

		response_json = [item.to_dict() for item in response]
		return response_json

	""" Endor-specific APIs: Workflows """

	def create_workflow(self, id: str, project_id: str, language_model: dict, data_retrieval: dict,
						pre_guardrail: dict = None, post_guardrail: dict = None, workflow_type: str = None, rag_fusion: bool = False,
						conversation: dict = None, query_reformulation: dict = None, intents: dict = None) -> Workflow:
		"""
		Creates a Workflow

		To facilitate the creation of workflows, Endor offers a collection of pre-configured templates.
		Creating a workflow involves selecting a template and specifying the configurations for each node within it.
		Each Workflow may include only the nodes defined in the selected template.

		View a list of all the fields in each key.
		[View fields â€º](https://docs.endor.apple.com/AML-Endor/endor-documentation/api-reference/#/operations/createWorkflow)

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient, Workflow

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		workflow: Workflow = endor_client.create_workflow(id='my-workflow', project_id='my-project',
														  language_model={'model_id': 'â€¦', â€¦},
														  data_retrieval={'embedding_model': 'â€¦', â€¦})
		print(workflow.id)
		# d0255948-c49e-â€¦
		```

		@param id(str): The ID of the new Workflow you'd like to create. Must be between 2 and 64 characters and should not contains spaces
		@param project_id(str): The ID of the Project this workflow should belong to
		@param language_model(dict): Details of the model used for this Workflow
		@param data_retrieval(dict): Details of the embedding model and filters
		@param pre_guardrail(dict): (Optional) Whether pre-guardrails are enabled and a list of them
		@param post_guardrail(dict): (Optional) Whether post-guardrails are enabled and a list of them
		@param workflow_type(str): (Optional) The type of workflow. Allowed values: `smart_answer`, `semantic_search`, `intent_route`, `free_prompt`, `lookup`. Defaults to `smart_answer`.
		@param rag_fusion(bool): (Optional) Enables Rag Fusion. Defaults to False.
		@param conversation(dict): (Optional) Conversation settings: `conversation_size` (int, 1-10, default 2), `include_responses` (bool, default True), `cache_ttl` (int, 1-604800, default 14400).
		@param query_reformulation(dict): (Optional) Query reformulation settings.
		@param intents(dict): (Optional) A dictionary of intents, mapping string keys to string values.
		@return (Workflow): The new Workflow
		"""

		if not pre_guardrail:
			pre_guardrail = {'enabled': False, 'guardrails': []}

		if not post_guardrail:
			post_guardrail = {'enabled': False, 'guardrails': []}

		# Optional parameters - only add to kwargs if not None
		optional_kwargs = {}
		if workflow_type is not None:
			optional_kwargs['workflow_type'] = workflow_type
		if rag_fusion is not None:
			optional_kwargs['rag_fusion'] = rag_fusion
		if conversation is not None:
			optional_kwargs['conversation'] = conversation
		if query_reformulation is not None:
			optional_kwargs['query_reformulation'] = query_reformulation
		if intents is not None:
			optional_kwargs['intents'] = intents
		if pre_guardrail is not None:
			optional_kwargs['pre_guardrail'] = pre_guardrail
		if post_guardrail is not None:
			optional_kwargs['post_guardrail'] = post_guardrail

		# Call the SDK function
		response = self.sdk_client.workflows.create_workflow(
			project_id=project_id,
			workflow_id=id,
			language_model=language_model,
			data_retrieval=data_retrieval,
			**optional_kwargs
		)

		if not response:
			logger.warning('No response received for create_workflow')
			return None

		# Transform the response to match the expected return format
		workflow_data = response.to_dict()

		# Map the fields to match the expected Workflow object structure
		workflow_params = {
			'project_id': workflow_data.get('project_id', project_id),
			'id': workflow_data.get('workflow_id'),
			'workflow_type': workflow_data.get('workflow_type'),
			'rag_fusion': workflow_data.get('rag_fusion'),
			'language_model': workflow_data.get('language_model'),
			'data_retrieval': workflow_data.get('data_retrieval'),
			'conversation': workflow_data.get('conversation'),
			'query_reformulation': workflow_data.get('query_reformulation'),
			'pre_guardrail': workflow_data.get('pre_guardrail'),
			'post_guardrail': workflow_data.get('post_guardrail'),
			'intents': workflow_data.get('intents'),
			'created_by': workflow_data.get('created_by'),
			'created_at': workflow_data.get('created_at'),
			'modified_by': workflow_data.get('updated_by'),
			'modified_at': workflow_data.get('updated_at'),
			'client': self
		}

		# Add optional fields if they exist in the response
		if 'enable_sor' in workflow_data:
			workflow_params['enable_sor'] = workflow_data.get('enable_sor')
		if 'self_rag' in workflow_data:
			workflow_params['self_rag'] = workflow_data.get('self_rag')
		if 'answer_style' in workflow_data:
			workflow_params['answer_style'] = workflow_data.get('answer_style')

		return Workflow(**workflow_params)


	def update_workflow(self, workflow_id: str, project_id: str, language_model: dict = None, data_retrieval: dict = None,
						pre_guardrail: dict = None, post_guardrail: dict = None, workflow_type: str = None,
						conversation: dict = None, query_reformulation: dict = None) -> Workflow:
		"""
		Updates a Workflow

		To facilitate the update of workflows, Endor offers a collection of pre-configured templates.
		Updation a workflow involves selecting a template and specifying the configurations for each node within it.
		Each Workflow may include only the nodes defined in the selected template.

		View a list of all the fields in each key.
		[View fields â€º](https://docs.endor.apple.com/AML-Endor/endor-documentation/api-reference/#/operations/updateWorkflow)

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient, Workflow

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		workflow: Workflow = endor_client.update_workflow(id='my-workflow', project_id='my-project',
														  language_model={'model_id': 'â€¦', â€¦},
														  data_retrieval={'embedding_model': 'â€¦', â€¦})
		print(workflow.id)
		# d0255948-c49e-â€¦
		```

		@param id(str): The ID of the new Workflow you'd like to create. Must be between 2 and 64 characters and should not contains spaces
		@param project_id(str): The ID of the Project this workflow should belong to
		@param language_model(dict): Details of the model used for this Workflow
		@param data_retrieval(dict): Details of the embedding model and filters
		@param pre_guardrail(dict): (Optional) Whether pre-guardrails are enabled and a list of them
		@param post_guardrail(dict): (Optional) Whether post-guardrails are enabled and a list of them
		@param workflow_type(str): (Optional) The type of workflow. Allowed values: `smart_answer`, `semantic_search`, `intent_route`, `free_prompt`, `lookup`. Defaults to `smart_answer`.
		@param rag_fusion(bool): (Optional) Enables Rag Fusion. Defaults to False.
		@param conversation(dict): (Optional) Conversation settings: `conversation_size` (int, 1-10, default 2), `include_responses` (bool, default True), `cache_ttl` (int, 1-604800, default 14400).
		@param query_reformulation(dict): (Optional) Query reformulation settings.
		@param intents(dict): (Optional) A dictionary of intents, mapping string keys to string values.
		@return (Workflow): The new Workflow
		"""

		# Optional parameters - only add if not None
		optional_kwargs = {}

		if language_model is not None:
			optional_kwargs['language_model'] = language_model
		if data_retrieval is not None:
			optional_kwargs['data_retrieval'] = data_retrieval
		if pre_guardrail is not None:
			optional_kwargs['pre_guardrail'] = pre_guardrail
		if post_guardrail is not None:
			optional_kwargs['post_guardrail'] = post_guardrail
		if workflow_type is not None:
			optional_kwargs['workflow_type'] = workflow_type
		if conversation is not None:
			optional_kwargs['conversation'] = conversation
		if query_reformulation is not None:
			optional_kwargs['query_reformulation'] = query_reformulation

		response = self.sdk_client.workflows.update_workflow(
			project_id=project_id,
			workflow_id=workflow_id,
			**optional_kwargs
		)

		if not response:
			logger.warning('No response received for update_workflow')
			return None

		workflow_data = response.to_dict()

		# Map the response to Workflow parameters
		workflow_params = {
			'project_id': workflow_data.get('project_id', project_id),
			'id': workflow_data.get('workflow_id'),
			'workflow_type': workflow_data.get('workflow_type'),
			'rag_fusion': workflow_data.get('rag_fusion'),
			'language_model': workflow_data.get('language_model'),
			'data_retrieval': workflow_data.get('data_retrieval'),
			'conversation': workflow_data.get('conversation'),
			'query_reformulation': workflow_data.get('query_reformulation'),
			'pre_guardrail': workflow_data.get('pre_guardrail'),
			'post_guardrail': workflow_data.get('post_guardrail'),
			'intents': workflow_data.get('intents'),
			'created_by': workflow_data.get('created_by'),
			'created_at': workflow_data.get('created_at'),
			'modified_by': workflow_data.get('updated_by'),
			'modified_at': workflow_data.get('updated_at'),
			'client': self
		}

		# Add optional fields if they exist in the response
		if 'enable_sor' in workflow_data:
			workflow_params['enable_sor'] = workflow_data.get('enable_sor')
		if 'self_rag' in workflow_data:
			workflow_params['self_rag'] = workflow_data.get('self_rag')
		if 'answer_style' in workflow_data:
			workflow_params['answer_style'] = workflow_data.get('answer_style')

		return Workflow(**workflow_params)


	def get_workflows(self, project_id: str) -> list[Workflow]:
		"""
		Returns all Workflows

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient, Workflow

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		workflows: list[Workflow] = endor_client.get_workflows(project_id='d0255948-c49e-â€¦')
		print(workflows)
		# [Workflow(â€¦), Workflow(â€¦), â€¦]
		```

		@param project_id(str): The ID of the Endor project you'd like to get Workflows for
		@return (list): A list of all available Workflow
		"""
		response = self.sdk_client.workflows.list_workflows(project_id=project_id)

		if not response:
			logger.warning('No response received for get_workflows')
			return []

		workflows: list[Workflow] = []
		for raw_workflow in response:
			workflow_data = raw_workflow.to_dict()
			workflow_params = {
			'project_id': workflow_data.get('project_id', project_id),
            'id': workflow_data.get('workflow_id'),
            'workflow_type': workflow_data.get('workflow_type'),
            'rag_fusion': workflow_data.get('rag_fusion'),
            'language_model': workflow_data.get('language_model'),
            'data_retrieval': workflow_data.get('data_retrieval'),
            'conversation': workflow_data.get('conversation'),
            'query_reformulation': workflow_data.get('query_reformulation'),
            'pre_guardrail': workflow_data.get('pre_guardrail'),
            'post_guardrail': workflow_data.get('post_guardrail'),
            'intents': workflow_data.get('intents'),
            'created_by': workflow_data.get('created_by'),
            'created_at': workflow_data.get('created_at'),
            'modified_by': workflow_data.get('updated_by'),
            'modified_at': workflow_data.get('updated_at'),
            'client': self
        }

			# Add optional fields if they exist in the response
			if 'enable_sor' in workflow_data:
				workflow_params['enable_sor'] = workflow_data.get('enable_sor')
			if 'self_rag' in workflow_data:
				workflow_params['self_rag'] = workflow_data.get('self_rag')
			if 'answer_style' in workflow_data:
				workflow_params['answer_style'] = workflow_data.get('answer_style')

			workflows.append(Workflow(**workflow_params))

		return workflows


	def get_workflow(self, id: str, project_id: str) -> Workflow:
		"""
		Returns the details of a given Workflow

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient, Workflow

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		workflow: Workflow = endor_client.get_workflow(id='my-workflow', project_id='d0255948-c49e-â€¦')
		print(workflow)
		# Workflow(â€¦)
		```

		@param id(str): The ID of the workflow (e.g. `enterprise_support_workflow`)
		@param project_id(str): The ID of your team's Endor project
		@return (Workflow): The Workflow
		"""

		response = self.sdk_client.workflows.view_workflow(project_id=project_id, workflow_id=id)

		if not response:
			logger.warning('No response received for get_workflow')
			return None

		workflow_data = response.to_dict()

		# Map the response to Workflow parameters - Re-using in multiple functions - move to helper function inside Workflow class
		workflow_params = {
			'project_id': workflow_data.get('project_id', project_id),
			'id': workflow_data.get('workflow_id'),
			'workflow_type': workflow_data.get('workflow_type'),
			'rag_fusion': workflow_data.get('rag_fusion'),
			'language_model': workflow_data.get('language_model'),
			'data_retrieval': workflow_data.get('data_retrieval'),
			'conversation': workflow_data.get('conversation'),
			'query_reformulation': workflow_data.get('query_reformulation'),
			'pre_guardrail': workflow_data.get('pre_guardrail'),
			'post_guardrail': workflow_data.get('post_guardrail'),
			'intents': workflow_data.get('intents'),
			'created_by': workflow_data.get('created_by'),
			'created_at': workflow_data.get('created_at'),
			'modified_by': workflow_data.get('updated_by'),
			'modified_at': workflow_data.get('updated_at'),
			'client': self
		}

		# Add optional fields if they exist in the response
		if 'enable_sor' in workflow_data:
			workflow_params['enable_sor'] = workflow_data.get('enable_sor')
		if 'self_rag' in workflow_data:
			workflow_params['self_rag'] = workflow_data.get('self_rag')
		if 'answer_style' in workflow_data:
			workflow_params['answer_style'] = workflow_data.get('answer_style')

		return Workflow(**workflow_params)


	def run_workflow(self, messages: list[dict], id: str, project_id: str, session_id: str = None,
					 return_trace_info: bool = False, filters: dict = None) -> list:
		"""
		Runs a given Workflow

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		EndorClient(app_id='â€¦', app_password='â€¦').run_workflow(messages=[â€¦], id='my-workflow', project_id='d0255948-c49e-â€¦')
		```

		@param messages(list): A list of messages (can be created using `.create_message(â€¦)`)
		@param id(str): The ID of the workflow (e.g. `enterprise_support_workflow`)
		@param project_id(str): The ID of your team's Endor project
		@param session_id(str): (Optional) A session ID for conversational context
		@param return_trace_info(bool): (Optional) Whether to return the run results of the individual nodes
		@return (list): a list of summary text
		"""

		response = self.sdk_client.workflows.execute_workflow(
                    project_id=project_id,
                    workflow_id=id,
                    message=messages[0] if messages else None,
                    filters=filters,
                    return_trace_info=return_trace_info)

		if not response:
			logger.warning('No response received for run_workflow')
			return []

		return response.to_dict()


	def delete_workflow(self, id: str, project_id: str) -> None:
		"""
		Deletes a Workflow

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		EndorClient(app_id='â€¦', app_password='â€¦').delete_workflow(id='my-workflow', project_id='d0255948-c49e-â€¦')
		```

		@param id(str): The ID of the workflow (e.g. `enterprise_support_workflow`)
		@param project_id(str): The ID of your team's Endor project
		"""

		response = self.sdk_client.workflows.delete_work_flow(project_id=project_id, workflow_id=id)
		return response # None returned in delete_workflow

	def submit_feedback(self, id: str, project_id: str, interaction_id: str, component: str, type: str,
                        session_id: str = None, additional_info: dict[str, Any] = None) -> dict[str, Any]:
		"""
		Submits feedback on the quality of the workflow execution response.

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		EndorClient(app_id='â€¦', app_password='â€¦').submit_feedback(id='my-workflow', project_id='d0255948-c49e-â€¦',
																 interaction_id='your_interaction_id',
																 component='smart_answer',  # Example component
																 type='thumbsUp',          # Example type
																 session_id='optional_session_id',
																 additional_info={'comment': 'Great response!'})
		```

		@param id(str): The ID of the workflow (e.g. `enterprise_support_workflow`)
		@param project_id(str): The ID of your team's Endor project
		@param interaction_id (str): The ID received from a successful workflow execution.
		@param component (str): The focus of the feedback (e.g., 'smart_answer', 'semantic_search'). Allowed values: `smart_answer`, `semantic_search`, `intent_route`, `free_prompt`, `lookup`
        @param type (str): The type of feedback (e.g., 'thumbsUp', 'thumbsDown'). Allowed values: `selected`, `paginated`, `thumbsUp`,  `thumbsDown`, `rating`, `thumbsUpReasoning`, `thumbsDownReasoning`
        @param session_id (str):  (Optional) A unique identifier for the executed workflow.
		@param additional_info (dict[str, Any]): (Optional) Additional information about the feedback.
		@return (dict[str, Any]): The feedback submission response.  Contains a 'response' key with the value 'Accepted'.
		"""

		response = self.sdk_client.workflows.submit_feedback(
			project_id=project_id,
			workflow_id=id,
			interaction_id=interaction_id,
			component=component,
			type=type,
			session_id=session_id,
			additional_info=additional_info
		)

		if not response or not response.response:
			logger.warning('No response received for submit_feedback')
			return None

		return response.to_dict()

	""" Endor-specific APIs: Products """

	def get_summary(self, text: str) -> list:
		"""
		Returns the summary for a given text content

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		summaries: list[str] = endor_client.get_summary(text=open('file.txt', 'r').read())
		print(summaries)
		# ['Endor is an Apple-internal platform', 'Endor provides APIsâ€¦']
		```

		@param text(str): the text to summarize (minimum: 15 characters)
		@return (list): a list of summary text
		"""

		if len(text) < 15:
			return text

		response = self.sdk_client.products.generate_summary(text=text)

		if not response or not response.summary:
			logger.warning('No response received for get_summary')
			return []

		return response.summary

	def get_questions(self, text: str) -> list:
		"""
		Generates and returns a list of questions for a given text content

		**How to use**
		```python
		from interlinked.core.clients.endorclient import EndorClient

		endor_client: EndorClient = EndorClient(app_id='â€¦', app_password='â€¦')
		questions: list[str] = endor_client.get_questions(text=open('file.txt', 'r').read())
		print(questions)
		# ['â€¦', 'â€¦']
		```

		@param text(str): the text to generate questions for
		@return (list): a list of questions
		"""
		response = self.sdk_client.products.generate_questions(text=text)

		if not response or not response.questions:
			logger.warning('No response received for get_questions')
			return []

		return response.questions

	@property
	def agents(self) -> AgentsApi:
		"""
        Access the Agents API directly.

        This property provides direct access to the SDK's AgentsApi, allowing
        for operations like creating, listing, and executing agents.

        Returns:
            AgentsApi: The agents API interface
        """
		return self.sdk_client.agents

	@property
	def answer_accuracy(self) -> AnswerAccuracyApi:
		"""
        Access the Answer Accuracy API directly.
        This property provides direct access to the SDK's AnswerAccuracyApi.

        Returns:
            AnswerAccuracyApi: The answer accuracy API interface
        """
		return self.sdk_client.answer_accuracy

	@property
	def guardrails(self) -> GuardrailsApi:
		"""
		Access the Guardrails API directly.

		This property provides direct access to the SDK's GuardrailsApi, allowing
		for operations like creating, listing, and executing guardrails.
		"""
		return self.sdk_client.guardrails

	@property
	def completions(self) -> CompletionsApi:
		"""
		Access the Completions API directly.

		This property provides direct access to the SDK's CompletionsApi
		"""
		return self.sdk_client.completions


	@property
	def chat_completions(self) -> ChatCompletionsApi:
		"""
		Access the Chat Completions API directly.

		This property provides direct access to the SDK's ChatCompletionsApi.
		"""
		return self.sdk_client.chat_completions

	@property
	def document_processing(self) -> DocumentProcessingApi:
		"""
		Access the Document Processing API directly.

		This property provides direct access to the SDK's DocumentProcessingApi, allowing
		for operations like parsing documents, split pdf to pages, parsecontent, etc
		"""
		return self.sdk_client.document_processing

	@property
	def embeddings(self) -> EmbeddingsApi:
		"""
		Access the Embeddings API directly.

		This property provides direct access to the SDK's EmbeddingsApi, allowing
		for operations like creating, listing, and executing embeddings.
		"""
		return self.sdk_client.embeddings

	@property
	def ingestions(self) -> IngestionsApi:
		"""
		Access the Ingestions API directly.

		This property provides direct access to the SDK's IngestionsApi, allowing
		for operations like creating, listing, and executing ingestions.
		"""
		return self.sdk_client.ingestions

	@property
	def models(self) -> ModelsApi:
		"""
		Access the Models API directly.

		This property provides direct access to the SDK's ModelsApi, allowing
		for operations like creating, listing, and executing models.
		"""
		return self.sdk_client.models

	@property
	def products(self) -> ProductsApi:
		"""
		Access the Products API directly.

		This property provides direct access to the SDK's ProductsApi, allowing
		for operations like creating, listing, and executing products.
		"""
		return self.sdk_client.products

	@property
	def projects(self) -> ProjectsApi:
		"""
		Access the Projects API directly.

		This property provides direct access to the SDK's ProjectsApi, allowing
		for operations like creating, listing, and executing projects.
		"""
		return self.sdk_client.projects

	@property
	def structured_ingestions(self) -> StructuredIngestionsApi:
		"""
		Access the Structured Ingestions API directly.

		This property provides direct access to the SDK's StructuredIngestionsApi, allowing
		for operations like creating, listing, and executing structured ingestions.
		"""
		return self.sdk_client.structured_ingestions

	@property
	def workflows(self) -> WorkflowsApi:
		"""
		Access the Workflows API directly.

		This property provides direct access to the SDK's WorkflowsApi, allowing
		for operations like creating, listing, and executing workflows.
		"""
		return self.sdk_client.workflows


TOOLS_SYSTEM_PROMPT: str =  \
'''
You are an assistant with access to the functions below. If the user's prompt requires using any of the tools below, respond with the exact JSON format below:
{"name": "function_name", "arguments": {}}

If you respond with the above, a function will be called and its response will be returned to you. Your task is to either:
- Repeat the response back to the user or
- Call the next function if necessary

---
'''


if __name__ == '__main__':

	observation = AI.ask(template='Hey! How is it going?',
						 client=EndorClient(model_name='endor-text-gemini-1.5-latest', app_id=Config.current.IDMS_APP_ID,
											app_password=Config.current.IDMS_APP_PASSWORD))
	print(observation)