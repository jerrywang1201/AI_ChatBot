import uuid
import logging
from typing import Any

from interlinked.core.config import Config
from interlinked.core.utilities import Utilities
from interlinked.core.singleton import SingletonMeta
from interlinked.core.clients.basevectorstoreclient import BaseVectorStoreClient

logger = logging.getLogger(__name__)

try:
    from elasticsearch import Elasticsearch
    from elastic_transport import ObjectApiResponse

except ModuleNotFoundError:

    logger.section('installing elasticsearchâ€¦')
    Utilities.install_package('elasticsearch')

    from elasticsearch import Elasticsearch
    from elastic_transport import ObjectApiResponse


class ElasticSearchClient(Elasticsearch, BaseVectorStoreClient, metaclass=SingletonMeta):
    """
    A ElasticSearch client specifically designed for storing Knowledge
    """

    def __init__(self, username: str = None, password: str = None, host: str = None,
                 port: str = None, cloud_id: str = None, **kwargs):
        """
        Initializes the ElasticSearch vector store/database

        @param host(str): (Optional) The ElasticSearch host name if you're hosting ElasticSearch
        You can pass cloud_id, if you're using cloud using env variable
        ðŸ‘¤: Username and ðŸ”: password are passed through env variable
        """

        username: str = username or Config.current.ELASTICSEARCH_USERNAME
        password: str = password or Config.current.ELASTICSEARCH_PASSWORD
        cloud_id = cloud_id or Config.current.ELASTICSEARCH_CLOUD_ID
        host: str = host or Config.current.ELASTICSEARCH_HOSTNAME

        if not host and not cloud_id:
            raise Exception('Both host and Cloud ID are not defined. Please pass either.')

        if cloud_id:
            kwargs['cloud_id'] = cloud_id

        else:
            kwargs['hosts'] = [host]

        basic_auth: tuple[str, str] = (username, password)
        super(ElasticSearchClient, self).__init__(basic_auth=basic_auth, **kwargs)

    @SingletonMeta.Shared
    def shared(cls) -> 'ElasticSearchClient':
        return cls(shared=True)

    def create_collection(self, name: str, size: int) -> None:
        """
        Creates an index if it doesn't exist already

        @param name(str): the name of the collection
        @param size(int): the vector size (varies based on model)
        """

        if self.indices.exists(index=name):
            raise Exception('Index already exists.')
        else:
            self.indices.create(
                index=name,
                mappings={
                    'properties': {
                        'payload': {
                            'type': 'nested',
                            'properties': {
                                'content': {'type': 'text'},
                                'knowledge_source_id': {'type': 'text'},
                                'external_id': {'type': 'text'},
                                'content_hash': {'type': 'text'},
                            }
                        },
                        'vector':
                            {'type': 'dense_vector', 'dims': size}
                    }
                },
            )

    def delete_collection(self, name: str) -> None:
        """
        Deletes an index

        @param name(str): the name of the collection
        """

        if not self.indices.exists(index=name):
            logger.info('Index does not exists')
            return

        self.indices.delete(index=name)

    def get_has_collection(self, name: str) -> bool:
        """
        Returns whether a given index exists

        @param name(str): the name of the collection
        @return (bool): True if contain else False
        """

        try:
            return self.indices.exists(index=name)

        except:
            return False

    def retrieve(self, id: str, collection_name: str) -> ObjectApiResponse[Any] | list[Any]:
        """
        Get the content and embeddings for a given document using id

        @param id(str): the name of the ID key to use for finding the document
        @param collection_name(str): the name of the index to store the knowledge in

        @return (ObjectApiResponse): Document object of ElasticSearch
        """

        # if we've never seen or initialized the index
        if not self.get_has_collection(name=collection_name):
            raise Exception('Index does not exists.')

        else:

            try:
                return super(ElasticSearchClient, self).get(index=collection_name, id=id)

            except:
                return []

    def upsert(self, embedding: list[float], payload: dict[str, Any], collection_name: str) -> str:
        """
        Adds an embedding to a given index

        @param embedding(float): the embedding
        @param payload(str): the string/text content used to generate the embedding
        @param collection_name(str): the name of the index to store the knowledge in
        @return (str): the newly-generated ID of the point/embedding
        """

        # if we've never seen or initialized the index, create one and use the size of the embedding
        if not self.get_has_collection(name=collection_name):
            self.create_collection(name=collection_name, size=len(embedding))

        id: str = str(uuid.uuid4())

        request: dict[str, Any] = {
            'vector': list(embedding),
            'payload': payload
        }

        super(ElasticSearchClient, self).index(index=collection_name, id=id, body=request)
        self.indices.refresh(index=collection_name)
        return id

    def update(self, id: str, embedding: list[float], payload: dict[str, Any], collection_name: str) -> None:
        """
        Update an embedding to a given collection

        @param id(str): the name of the ID key to use for finding the document
        @param embedding(float): the embedding
        @param payload(str): the string/text content used to generate the embedding
        @param collection_name(str): the name of the index to store the knowledge in
        """

        body: dict[str, Any] = {
            'payload': payload,
            'vector': embedding
        }
        super(ElasticSearchClient, self).update(index=collection_name, id=id, doc=body)
        self.indices.refresh(index=collection_name)

    def delete(self, id: str, collection_name: str) -> None:
        """
        Deletes an embedding from a given index

        @param id(str): the name of the ID key to use for finding the document
        @param collection_name(str): the name of the index to store the knowledge in
        """

        if not self.get_has_collection(name=collection_name):
            raise Exception('Index does not exists.')

        super(ElasticSearchClient, self).delete(index=collection_name, id=id)

    def search(self, query_vector: list[float], collection_name: str, limit: int = 1,
               score_threshold: float = 0, query_filter: dict = None) -> dict:
        """
        Search K nearest neighbour based on cosine similarity

        @param query_vector(list[float]): the embedding
        @param collection_name(str): the name of the collection the knowledge is stored in
        @param score_threshold(float): fetch documents with greater than this value
        @param query_filter(dict): fetch the documents based on a query filter

        @return (dict): list of documents
        """
        elastic_version = int(super(ElasticSearchClient, self).info()['version']['number'][0])

        # new elastic search supported KNN query which is much faster than cosine similarity
        if elastic_version < 8:

            query: dict = {
                'query': {
                    'bool': {
                        'must': [{
                            'function_score': {
                                'script_score': {
                                    'script': {
                                        'params': {'query_vector': query_vector},
                                        'source': '(1.0+cosineSimilarity(params.query_vector, \'vector\'))',
                                    }
                                }
                            }
                        }]
                    }
                },
                'size': limit,
                'min_score': score_threshold
            }

            if query_filter:

                query_filter_template = {
                    'nested': {
                        'path': 'payload',
                        'query': {
                            'bool': {'must': query_filter}
                        }
                    }
                }
                query['query']['bool']['must'].append(query_filter_template)

            return super(ElasticSearchClient, self).search(index=collection_name, body=query).get('hits', []).get('hits', [])

        query: dict[str, Any] = {

            'k': limit,
            'field': 'vector',
            'query_vector': query_vector,
        }

        if query_filter:

            query_filter_template = {
                'nested': {
                    'path': 'payload',
                    'query': {
                        'bool': {'must': query_filter}
                    }
                }
            }
            query['filter'] = query_filter_template

        return super(ElasticSearchClient, self).search(knn=query, min_score=score_threshold, size=k).  \
                                                get('hits', []).get('hits', [])

    def _search_by_content_hash_or_knowledge_source(self, collection_name: str, content_hash: str = None,
                                                    knowledge_source_id: int = None):
        """
        Internal Use only
        """
        if not (content_hash or knowledge_source_id):
            raise Exception('Content Hash or Knowledge Source id must not be null')

        try:
            query = {
                'query': {
                    'nested': {
                        'path': 'payload',
                        'query': {
                            'bool': {
                                'should': [
                                ]
                            }
                        }
                    }
                }
            }

            if content_hash:
                content_hash_source = {'match': {'payload.content_hash': content_hash}}
                query['query']['nested']['query']['bool']['should'].append(content_hash_source)

            if knowledge_source_id:
                knowledge_source = {'match': {'payload.knowledge_source_id': knowledge_source_id}}
                query['query']['bool']['should'].append(knowledge_source)

            return super(ElasticSearchClient, self).search(index=collection_name, body=query).get('hits', []).get('hits', [])

        except:
            return []

    def search_by_query(self, collection_name: str, query: dict) -> dict:
        """
        Search using elastic search query

        @param collection_name(str): the name of the collection the knowledge is stored in
        @param query(dict): the embedding

        @return (dict): list of documents
        """
        return super(ElasticSearchClient, self).search(index=collection_name, body=query).get('hits', [])
