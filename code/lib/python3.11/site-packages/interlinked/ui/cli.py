import sys

# check python version
if sys.version_info < (3, 11):

	print('\033[93m ‚ö†Ô∏è Your default Python version is too old. Please upgrade to the latest Python via https://www.python.org/downloads')
	sys.exit(4)

import os
import json
import logging
import readline
import threading
import importlib
import subprocess
from typing import Any
from pathlib import Path
from datetime import datetime

from interlinked.core.config import Config
from interlinked.core.utilities import Utilities
from interlinked.core.ai import AI, Knowledge, UserError

logger = logging.getLogger(__name__)


class CLI:

	# the name of the file this CLI will write history to
	# and other user preferences
	CONFIGURATION_FILE_PATH: str = f'{Path.home()}/.interlinked-cli'

	# conditionally print colors if the console/terminal supports it
	SUPPORTS_COLOR: bool = sys.stdout.isatty() and not os.getenv('NO_COLOR')

	BOLD: str = '\33[1m'
	RED: str = '\033[31m'
	GRAY: str = '\033[90m'
	BLINK: str = '\033[5m'
	YELLOW: str = '\033[33m'
	LINE_END: str = '\033[0m'
	GREEN: str = '\33[1m\33[92m'
	BRIGHT_CYAN: str = '\033[96m'
	BOLD_GREEN: str = '\33[1m\33[92m'
	BOLD_RED: str = '\33[1m\033[31m'

	@classmethod
	def main(cls):
		"""
		- no args: runs the platform
		"""

		# check if there's an update
		if Config.current.is_development and not Config.current.NO_UPDATE:

			def check_for_update() -> None:
				"""
				Checks for updates and prints any new update
				"""

				try:

					cli_configuration: dict[str, Any] = cls.get_cli_configuration()

					package_name: str = 'apple-interlinked'
					installed_version: str = Utilities.get_installed_version(package_name=package_name)

					# check if we already cached the latest/next version
					latest_version: str = cli_configuration.get('latest_version')

					if not latest_version or installed_version >= latest_version:
						latest_version = Utilities.get_latest_version(package_name=package_name)

						# cache the version/build
						cli_configuration['latest_version'] = latest_version

						with open(cls.CONFIGURATION_FILE_PATH, 'w') as file:
							json.dump(cli_configuration, file)

					if latest_version > installed_version:

						print(f'{cls.GREEN if cls.SUPPORTS_COLOR else ""}{"=" * 40}')
						print(f'‚ú® {cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}Update available: {latest_version}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
						print(f'   {cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}Upgrade via:{cls.LINE_END if cls.SUPPORTS_COLOR else ""} pip{sys.version_info.major}.{sys.version_info.minor} install apple-interlinked -U -i https://pypi.apple.com/simple')
						print(f'{cls.GREEN if cls.SUPPORTS_COLOR else ""}{"=" * 40}\n')

				except:
					return

			threading.Thread(target=check_for_update).start()

		args: list[str] = sys.argv[1:]

		if not args:
			cls.run_platform()

		workflow_name: str = args[0]

		# If the first argument is a bundle ID (starts with 'com.')
		# Launch MCP server for that bundle
		if workflow_name.startswith('com.'):

			cls.run_mcp_server(bundle_id=workflow_name, args=args[1:])
			return

		if workflow_name == 'deploy':

			if len(args) > 1 and args[1] == 'reset':

				try:
					os.remove('~/.interlinked-kube.yaml')

				except FileNotFoundError:
					pass

				logger.info('deployment configuration reset successfully. you can reconfigure Kube deployment using `interlinked deploy`')
				return

			os.system(f'./deploy.sh')
			return

		elif workflow_name == 'automation':

			# check if redis is installed
			if Config.current.is_development:

				import shutil
				has_redis: bool = shutil.which('redis-server') is not None

				if not has_redis:

					logger.section('installing Redis‚Ä¶')
					os.system(f'brew install redis && brew services start redis')

			# `OBJC_DISABLE_INITIALIZE_FORK_SAFETY=yes` is only used on macOS
			os.system(f'OBJC_DISABLE_INITIALIZE_FORK_SAFETY=yes celery -A interlinked.ui.tasks worker -B -O fair -s /tmp/celerybeat-schedule')
			return

		# chat with AI
		elif workflow_name == 'chat':

			kwargs: dict[str, str] = cls.get_kwargs(ignore_unknown=True)

			if 'h' in kwargs or 'help' in kwargs:

				print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}Available options:{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
				print('--knowledge (-k)\t\tGives AI the ability to reply with knowledge it learned')
				print('--list-knowledges (-lk)\t\tLists all knowledge sources AI learned from')
				print('--list-clients (-lc)\t\tLists all AI clients available')
				print('--delete (-d)\t\t\tDeletes history and knowledge learned (including knowledge learned outside of chat)')
				print()
				print('--client (-c)\t\t\tThe AI client to use. See full list via `--list-clients (or -lc)`')
				print('--model (-m)\t\t\tThe AI model to use')
				print('--system-message (-sm)\t\t\tCustomize AI‚Äôs personality. Provide text instructions on what AI‚Äôs role is.')
				print('--completion (-t)\t\tCompletes a given text instead of chatting')
				print('--tools (-ts)\t\t\tGive AI access to call functions in a Python file via Function Calling (pass `.py` file path)')
				quit()

			# list knowledge sources
			if 'list-knowledges' in kwargs or 'lk' in kwargs:

				from interlinked.core.ai import Knowledge
				knowledge_source_ids: int = Knowledge.get_all_knowledge_source_ids()

				for knowledge_source_id in knowledge_source_ids:
					print(f'- {knowledge_source_id}')

				print(f'\n#Ô∏è‚É£  Total: {len(knowledge_source_ids)}')
				quit()

			# list clients
			if 'list-clients' in kwargs or 'lc' in kwargs:

				from textwrap import dedent
				from interlinked.core.ai import AI

				print()

				for client_index, client in enumerate(AI.CLIENTS.items()):

					client_name, client_class = client

					print(f'{cls.BOLD if cls.SUPPORTS_COLOR else ""}{client_name}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
					print(f'\t‚û°Ô∏è  {dedent(client_class.__doc__).strip()}')
					print(f'\tüìñ interlinked.apple.com/documentation?page={client_class.__name__}')
					print()

				print('\n‚ÑπÔ∏è  You can use any of the clients above via `interlinked chat --client=‚Ä¶`')
				print('üîí Some clients may require authentication')
				quit()

			# delete knowledge
			if 'delete' in kwargs or 'd' in kwargs:

				if os.path.exists(cls.CONFIGURATION_FILE_PATH):
					os.remove(cls.CONFIGURATION_FILE_PATH)

				# if the platform is installed, delete all Knowledge Configuration
				try:

					from interlinked.ui.models import BaseSQLModel, Configuration
					from interlinked.core.workflows.knowledge.workflow import CollectKnowledge

					BaseSQLModel.create_all_models()
					BaseSQLModel.migrate()

					configurations: list[Configuration] = Configuration.select().where(Configuration.workflow_name == CollectKnowledge.WORKFLOW_NAME).all()

					for configuration in configurations:
						configuration.delete()

				except ImportError as error:
					pass

				# delete all knowledge
				from interlinked.core.ai import Knowledge
				Knowledge.delete_all()

				print('ü§´ Successfully deleted history and forgot all knowledge')
				quit()

			# load previous input
			cli_configuration: dict[str, Any] = cls.get_cli_configuration()

			_kwargs: dict[str, str] = kwargs.copy()
			client_name: str = kwargs.pop('client', kwargs.pop('c', '')).lower()
			model_name: str = kwargs.pop('model', kwargs.pop('m', None))
			model_name = model_name.lower() if model_name else None
			use_knowledge: bool = 'knowledge' in kwargs or 'k' in kwargs
			completion: bool = 'completion' in kwargs or 't' in kwargs
			system_message: str = kwargs.pop('system_message', kwargs.pop('sm', None))

			tools: list[str] = []
			applet_names: list[str] = []

			if completion:
				kwargs.pop('completion', kwargs.pop('t', None))

			if system_message:
				kwargs.pop('system_message', kwargs.pop('sm', None))

			if _tools := kwargs.pop('tools', kwargs.pop('ts', None)):

				if _tools.startswith('com.'):

					import json
					from interlinked.core.applet import Applet

					for bundle_id in _tools.split(','):

						applet: Applet = Applet.get(bundle_id=bundle_id)
						applet_names.append(applet.name)

						function_kwargs: dict[str, Any] = cli_configuration.get('applets', {}).get(bundle_id, {})

						# check if this Applet requires kwargs and prompt user if needed
						if applet.kwargs:

							function_kwargs = cls.get_or_prompt_applet_kwargs(applet=applet, existing_kwargs=function_kwargs)

							# save the kwargs to CLI configuration for future use
							if 'applets' not in cli_configuration:
								cli_configuration['applets'] = {}

							cli_configuration['applets'][bundle_id] = function_kwargs

							# save to a file
							with open(cls.CONFIGURATION_FILE_PATH, 'w') as file:
								json.dump(cli_configuration, file)

						tools += applet.get_tools(function_kwargs=function_kwargs)

				else:

					from interlinked.core.tool import Tool

					# e.g. `--tools file.py,tools.py`
					tool_paths: list[str] = _tools.split(',')

					for tool_path in tool_paths:

						for function in Utilities.get_functions_in_file(path=tool_path):

							function_name: str = function['name']

							try:
								tool = Tool.get_tool_from_file(path=tool_path, function_name=function_name)

							except Exception as exception:

								logger.error(f'could not read function "{function_name=}"', exc_info=True)
								quit()

							if not tool.description or len(tool.description) <= 5:
								logger.error(f'{function_name=} is missing docstrings, which is the description underneath the function.'  \
											  'AI uses docstrings to understand what your function does and how to call it.')
							tools.append(tool)

			# if client/model names are passed as args instead of kwargs
			if not client_name:

				# get all of the arguments excluding kwargs
				# e.g. `interlinked chat ollama mixtral -h` -> `['ollama', 'mixtral']`
				flat_kwargs: list[str] = [key_or_value for argument in _kwargs.items() for key_or_value in argument]
				arguments: list[str] = [argument for argument in sys.argv[2:] if not argument.startswith('-') and argument.removeprefix('--').removeprefix('-').split('=', 1)[0] not in flat_kwargs]

				if arguments and len(arguments[0]) > 2:

					# e.g. `ollama` or `ollamaclient`
					client_name = arguments[0]

					# e.g. `mixtral` (optional)
					model_name = arguments[1] if len(arguments) > 1 else None

				else:
					client_name = Config.current.AI_CLIENT_NAME

			if not client_name.endswith('client'):
				client_name = f'{client_name}client'

			if use_knowledge:
				kwargs.pop('knowledge', kwargs.pop('k', None))

			from interlinked.core.ai import AI, Observation

			client: Any = AI.CLIENTS[client_name](model_name=model_name, **kwargs)

			if completion:
				print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}‚úèÔ∏è You are using completion. {client.model_name} will complete any text you enter.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

			else:
				print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üí¨ Hi! Thanks for chatting with me ({client.model_name}).{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

			knowledge_count: int = None
			knowledge_source_ids: list[int|str] = None

			if not completion:

				# if `-k` is passed, make sure there's Knowledge stored
				from interlinked.core.ai import Knowledge
				knowledge_source_ids: list[int|str] = Knowledge.get_all_knowledge_source_ids()
				knowledge_count: int = Knowledge.get_count()

				# if `-k` is passed and we have knowledge
				if use_knowledge and knowledge_count:

					if knowledge_source_ids:
						print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üìñ I will help answer questions from {len(knowledge_source_ids)} documents I learned from. My responses may be slower.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

					else:
						print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üìñ I will help answer questions from {knowledge_count} pieces of knowledge I learned from. My responses may be slower.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

					if client_name == 'ollamaclient':
						print(f'{cls.YELLOW if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è  {client_name} does not officially support chat with documents. Inaccurate results or errors may occur.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

					elif client_name == 'mlxclient':

						print(f'{cls.RED if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è  MLX does yet support Function Calling, which is needed to chat with documents. {cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
						quit()

				# if `-k` is not passed but we do have knowledge
				elif not use_knowledge and knowledge_count:
					print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üìñ To ask me about documents, run `interlinked chat -k` instead.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

				elif use_knowledge and not knowledge_count:

					use_knowledge = False
					print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üìñ I am have not learned from any files yet. Drag/drop .md and .rst files then start asking questions (one file at a time){cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

			if applet_names:
				print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üíª  I will use {", ".join(applet_names)} to help you.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

			elif tools:
				print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üíª  I will use the {len(tools)} functions you\'ve given me. My responses may be slower.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

			# start prompting for user input
			messages: list[dict] = []
			observation: Observation = None
			thread: threading.Thread = None

			if system_message:
				messages = [client.create_message(role=client.ROLE_SYSTEM, content=system_message)]

			while True:

				try:
					prompt: str = input(f'{f"{cls.BOLD}{cls.GRAY}" if cls.SUPPORTS_COLOR else ""}‚Üí{cls.LINE_END if cls.SUPPORTS_COLOR else ""} ').strip()

					if not prompt:
						continue

					thread = Spinner()
					thread.start()

					# if the prompt is a full file path, learn from the file
					if prompt.startswith('/') and (path := prompt.replace('\\ ', ' ')):

						if os.path.exists(path):

							print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üìñ Learning‚Ä¶{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

							try:
								AI.learn(from_=path, knowledge_source_id=path, client=client)

							except Exception as exception:

								thread.stop()

								if 'shapes' in str(exception):
									logger.error('Error: the previous documents I learned from were using another AI model. To continue, run `interlinked chat --delete` in another tab then try again.')

								else:
									logger.error(exception)

							else:

								thread.stop()
								print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}‚úÖ You can now ask me questions about this file{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

								if not use_knowledge and client_name in {'ollamaclient', 'mlxclient'}:
									print(f'{cls.YELLOW if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è  Ollama does not officially support chat with documents. Inaccurate results or errors may occur.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

								use_knowledge = True

							# print an empty line
							print()

							continue

						elif ' ' in path and os.path.exists(path.split()[0]):

							logger.error('Please drag and drop files one at a time')

							# print an empty line
							print()
							continue

					has_response: bool = False
					cls.save_prompt(prompt=prompt)

					if use_knowledge:

						from interlinked.core.workflows.agent.workflownonui import AgentNonUI

						observation, used_knowledges = AgentNonUI.handle_nonui_message(prompt=prompt, messages=messages, client=client, tools=tools)

						thread.stop()

						if observation:

							# print the response and knowledge sources
							print(f'{cls.BRIGHT_CYAN if cls.SUPPORTS_COLOR else ""}{observation.response.raw}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

						else:
							print('No response')

						continue

					__observation: Observation = None
					response: str = ''

					if completion:

						__observation = AI.ask(prompt=prompt, messages=messages, client=client, completion=completion)
						thread.stop()

						if __observation.response is not None:

							print(f'{cls.BRIGHT_CYAN if cls.SUPPORTS_COLOR else ""}{__observation.response.raw}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}', end='', flush=True)
							response = f'{response}{__observation.response.raw}'

					elif tools:

						thread.stop()

						# allow `max_iterations` in a controlled environment to be high enough to accomadate
						# use-cases, such as looking up Radars
						if observation := AI.ask(prompt=prompt, messages=messages, client=client, tools=tools, max_iterations=9999):

							# print the response and knowledge sources
							print(f'{cls.BRIGHT_CYAN if cls.SUPPORTS_COLOR else ""}{observation.response.raw}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

						else:
							print('No response')

						continue

					else:

						for _observation in AI.ask(prompt=prompt, messages=messages, client=client, stream=True) if not observation else observation.ask(prompt=prompt, stream=True):

							if not __observation:
								thread.stop()

							if _observation.response is not None:

								print(f'{cls.BRIGHT_CYAN if cls.SUPPORTS_COLOR else ""}{_observation.response.raw}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}', end='', flush=True)
								__observation = _observation
								response = f'{response}{_observation.response.raw}'

					# print an empty line
					print()

					observation = __observation
					observation.messages.append(client.create_message(role=client.ROLE_ASSISTANT, content=response.strip()))

				except (EOFError, KeyboardInterrupt) as error:

					if thread:
						thread.stop()

					print()
					print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üí¨ See you soon!{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
					quit()

				except Exception as exception:

					if thread:
						thread.stop()

					raise exception

			return

		elif workflow_name == 'learn':

			kwargs: dict[str, str] = cls.get_kwargs()
			from_: str = kwargs.pop('from', None)

			if not from_:

				logger.error('please pass an md/rst file path. e.g. `interlinked learn --from="/Users/my_name/Documents/file.md"`')
				quit()

			print('üìñ Learning‚Ä¶')
			from_ = from_.strip()

			# if the platform is installed, use `CollectKnowledge`, as it contains
			# all of the features built-in. Otherwise, fallback to the API
			try:

				from interlinked.ui.models import BaseSQLModel, KnowledgeSourceEnum
				from interlinked.core.workflows.knowledge.workflow import CollectKnowledge

				BaseSQLModel.create_all_models()
				BaseSQLModel.migrate()
				CollectKnowledge.run(from_=from_)

			except ImportError as error:
				AI.learn(from_=from_, knowledge_source_id=from_)

			print(f'\n{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}‚úÖ You can now chat with me about this file using `interlinked chat -k`{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
			quit()

		# enroll in beta
		elif workflow_name.replace('-', '') in {'enroll', 'e'}:

			import pathlib
			import requests
			from interlinked.core.applet import Applet

			kwargs: dict[str, str] = cls.get_kwargs(ignore_unknown=True)
			base_url: str = kwargs.get('base_url') or os.getenv('INTERLINKED_BETA_BASE_URL')

			if not base_url:

				print(f'{cls.BOLD_RED if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è  Missing `INTERLINKED_BETA_BASE_URL=‚Ä¶` or --base_url=‚Ä¶{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
				quit()

			# fetch from the server
			headers: dict[str, str] = {'accept': 'application/json', 'Authorization': f'Bearer {Applet.get_api_key(base_url=base_url)}'}
			response = requests.get(f'{base_url}/api/v1/beta-assets', headers=headers, allow_redirects=False)

			if not response.ok:

				print(f'{cls.BOLD_RED if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è  Could not enroll: {response.text}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
				quit()

			response_json: dict[str, Any] = response.json()
			files: dict[str, Any] = response_json.get('files', {})
			base_path: str = pathlib.Path(__file__).resolve().parent.parent.parent

			for relative_path, code in files.items():

				print(f'‚¨áÔ∏è  Installing {relative_path}‚Ä¶')

				with open(f'{base_path}/{relative_path}', 'w') as file:

					try:
						file.write(code)

					except Exception as exception:

						print(f'{cls.BOLD_RED if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è  Could not install: {exception}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
						quit()

			print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}‚úÖ Successfully enrolled and updated to beta{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
			quit()

		# internal to Interlinked
		elif workflow_name == 'listen':

			from interlinked.ui.listener import Listener
			Listener.shared

			while True: pass
			return

		# internal to Interlinked
		elif workflow_name == 'forward':

			commands: list[str] = [

				'kubectl port-forward svc/interlinked-qdrant 6333:6333 &',
				'kubectl port-forward svc/interlinked-qdrant 6334:6334 &',
				'kubectl port-forward svc/interlinked-postgres 5432:5432 &'
				'kubectl port-forward svc/interlinked-redis 6370:6379 &'
			]

			processes = []

			for cmd in commands:
				processes.append(subprocess.Popen(cmd, shell=True))

			for process in processes:
				process.wait()

			return

		# help
		if workflow_name.replace('-', '') in {'help', 'h'}:

			print('‚ÑπÔ∏è  Passing no options will run the platform, which includes AI Screener, Playground, and more‚Ä¶\n')

			print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}Available options:{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
			print('chat\t\tChat with AI!')
			print('learn\t\tAI can learn from md/rst files')
			print('publish\t\tPublish your Applet to interlinked.apple.com/applets')
			print('com.apple.*\tRun MCP server for an Applet (e.g., interlinked com.apple.quip)')

			print()
			print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}Build:{cls.LINE_END if cls.SUPPORTS_COLOR else ""} {importlib.metadata.version("apple-interlinked")}')
			quit()

		elif workflow_name.replace('-', '') in {'publish', 'p'}:

			import json
			import shutil
			import platform
			from pathlib import Path
			from interlinked.core.applet import Applet, MissingDefinition

			kwargs: dict[str, str] = cls.get_kwargs(ignore_unknown=True)

			thread = Spinner()
			thread.start()

			applet: Applet = None
			applet_path: str = args[len(kwargs) + 1] if len(args) > len(kwargs) + 1 else str(Path.cwd())

			try:
				applet = Applet.publish(path=applet_path, **kwargs)
				thread.stop()

			except MissingDefinition:

				thread.stop()

				readme_content: str = None
				mcp_definition: dict[str, Any] = None

				if os.path.exists(f'{applet_path}/README.md'):

					from interlinked.core.tool import Tool

					with open(f'{applet_path}/README.md', 'r') as file:

						readme_content = file.read()
						mcp_definition = Tool.get_mcp_definition_from_string(string=readme_content)

				# auto-create definition
				if Config.current.is_development:

					definition_path: str = f'{applet_path}/applet.json'

					with open(definition_path, 'w') as file:

						definition: dict[str, Any] = {

							'name': 'Your Applet name',
							'bundle_id': 'com.apple._____',
							'category': 'other',

							'summary': 'A one-line summary of your Applet.',
							'description': 'README.md' if readme_content else 'A long description of your Applet.'
						}

						# auto-populate the name/bundle ID from the Readme
						if mcp_definition:

							if len(list(mcp_definition.keys())) == 1:

								name: str = list(mcp_definition.keys())[0]
								definition['name'] = name.replace('-', ' ').replace('_', ' ').title()
								definition['bundle_id'] = f'com.apple.{name.replace(" ", "_").replace("-", "_").lower()}'

							definition['mcp'] = mcp_definition

						# auto-populate `summary` from Readme
						if readme_content:

							from interlinked.core.ai import Section
							from interlinked.core.parsers.markdownparser import MarkdownParser

							section: Section = MarkdownParser.get_section_for_markdown(content=readme_content)

							if section.content and isinstance(section.content[0], str):
								definition['summary'] = section.content[0].split('.', 1)[0]

						file.write(json.dumps(definition, indent=4))

					# auto-add icon
					if not os.path.exists(f'{applet_path}/icon.png') and not os.path.exists(f'{applet_path}/icon.jpg'):

						ui_path: str = os.path.dirname(os.path.abspath(__file__))
						shutil.copy(f'{ui_path}/static/missing_applet_icon.jpg', f'{applet_path}/icon.jpg')

					# open in a text editor
					if platform.system() == 'Darwin':

						preferred_editor_name: str = None
						editor_names: list[str] = ['Sublime Text', 'Visual Studio Code', 'PyCharm']

						for editor_name in editor_names:

							if cls.get_is_process_running(name=editor_name):

								preferred_editor_name = editor_name
								break

						if preferred_editor_name:

							try:

								subprocess.run(['open', '-a', preferred_editor_name, definition_path], check=True)

							except subprocess.CalledProcessError:
								pass

						else:

							for editor_name in editor_names:

								try:

									subprocess.run(['open', '-a', editor_name, definition_path], check=True)
									break

								except subprocess.CalledProcessError:
									continue

					print(f'{cls.BOLD_RED if cls.SUPPORTS_COLOR else ""}‚û°Ô∏è  Complete the new `applet.json` file then run this command again{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

				else:
					print(f'{cls.BOLD_RED if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è  Your Applet folder is missing an `applet.json` file{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

				quit()

			except Exception as exception:

				thread.stop()
				print(f'{cls.BOLD_RED if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è  {exception}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
				raise

			print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}‚úÖ Published {applet.name}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
			print(f'{cls.GREEN if cls.SUPPORTS_COLOR else ""}{"=" * 40}')
			print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}URL:{cls.LINE_END if cls.SUPPORTS_COLOR else ""} interlinked.apple.com/applets?bundle_id={applet.bundle_id}')

			if not applet.mcp:
				print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}Functions:{cls.LINE_END if cls.SUPPORTS_COLOR else ""} {sum(len(file.get("tools", [])) for file in applet.files)}')

			quit()

		# start a workflow
		from interlinked.ui.models import BaseSQLModel, BaseWorkflow, Configuration

		# ensure the database is initalized
		BaseSQLModel.create_all_models()

		module: Any = None

		try:
			module = importlib.import_module(f'interlinked.core.workflows.{workflow_name}.workflow')

		except ModuleNotFoundError:

			logger.error(f'"{workflow_name}" is not a valid workflow')
			quit()

		workflow: Any = next((cls for name, cls in vars(module).items() if isinstance(cls, type) and issubclass(cls, BaseWorkflow) and cls is not BaseWorkflow), None)

		if not workflow:
			raise ModuleNotFoundError()

		# start the configuration
		configuration: Configuration = None
		kwargs: dict[str, str] = cls.get_kwargs()

		if (configuration_id := args[1] if len(args) > 1 else None) and configuration_id.isnumeric():

			configuration: Configuration = Configuration.get_or_none(id=configuration_id)

			if configuration.workflow_name != workflow_name:

				logger.error(f'The ID you passed ({configuration_id}) is part of another workflow ({configuration.workflow_name}), not {workflow_name}')
				quit()

			if configuration:
				configuration.run(**kwargs)

		else:

			# run all configurations
			# e.g. `interlinked knowledge all` or `interlinked screen_radars all`
			if (first_argument := args[1] if len(args) > 1 else None) and first_argument == 'all':

				for configuration in Configuration.select().where(Configuration.workflow_name == workflow_name).all():
					configuration.run(**kwargs)

			else:
				workflow.run(**kwargs)

	@classmethod
	def run_platform(cls) -> None:
		"""
		Runs the platform on port 8000

		Used in development and production
		"""

		print(f'{cls.GREEN if cls.SUPPORTS_COLOR else ""}{"=" * 40}')
		print(f'{cls.BRIGHT_CYAN if cls.SUPPORTS_COLOR else ""}Running the platform (AI Screener, Talk to Your Documentation, and Playground)‚Ä¶')
		print(f'{cls.BLINK if cls.SUPPORTS_COLOR else ""}‚ÑπÔ∏è {f"{cls.LINE_END}{cls.BRIGHT_CYAN}" if cls.SUPPORTS_COLOR else ""} Looking to use the Python library? Running `interlinked` is not needed. See interlinked.apple.com/documentation')
		print('\nGot questions? We\'re here to help at #help-interlinked')
		print(f'{cls.GREEN if cls.SUPPORTS_COLOR else ""}{"=" * 40}{cls.BOLD if cls.SUPPORTS_COLOR else ""}\n\n')

		def _run_platform(_retry_count: int = 0) -> None:

			try:
				import uvicorn
				from interlinked.ui.listener import Listener
				from interlinked.ui.models import BaseSQLModel, BaseWorkflow, Configuration

			except ImportError as error:

				if _retry_count > 0:
					raise

				logger.section('installing platform‚Ä¶')
				Utilities.install_package('"apple-interlinked[ui]"')
				return _run_platform(_retry_count=_retry_count + 1)

			# stop any other process running on the same port
			if Config.current.is_development:

				import time

				def open_localhost():

					time.sleep(1)
					os.system('open http://localhost:8000')

				threading.Thread(target=open_localhost).start()
				os.system('kill -9 $(lsof -t -i :8000) 2>/dev/null')

			# auto-migrate
			try:
				BaseSQLModel.migrate()

			except Exception as exception:
				logger.error('could not migrate', exc_info=True)

			# start the Applet
			uvicorn.run('interlinked.ui.app:fast_api_app', host='0.0.0.0', port=8000, reload=str(Path.cwd()).endswith('interlinked'),
						workers=1 if Config.current.is_development else 4, timeout_graceful_shutdown=1,
						timeout_keep_alive=100)
			quit()

		_run_platform()

	@classmethod
	def run_mcp_server(cls, bundle_id: str, args: list[str]) -> None:
		"""
		Runs an MCP server for the specified bundle ID

		Example usage:
		  interlinked com.apple.quip --api_key=... --base_url=... --function_kwargs=...
		  interlinked com.apple.quip --sse --api_key=... --host=0.0.0.0 --port=3000

		@param bundle_id(str): The bundle ID of the applet to serve
		@param args(list): Additional command line arguments
		"""

		kwargs: dict[str, str] = {}
		use_sse: bool = False

		for arg in args:
			if arg.startswith('-'):

				key = arg[2:] if arg.startswith('--') else arg[1:]

				if '=' in key:
					key, value = key.split('=', 1)
				else:
					value = None

				if key in {'sse', 'stdio'}:

					use_sse = (key == 'sse')
					value = True if value is None else value

				elif value in {'true', 'True', 'T'}:
					value = True

				elif value in {'false', 'False', 'F'}:
					value = False

				elif value and value.isnumeric():
					value = int(value)

				kwargs[key] = value

			elif kwargs and list(kwargs.values())[-1] is None:
				kwargs[list(kwargs.keys())[-1]] = arg

		from interlinked.core.applet import Applet
		from interlinked.core.clients.mcpclient import MCPClient

		try:

			applet = Applet.get(bundle_id=bundle_id, api_key=kwargs.get('api_key'), base_url=kwargs.get('base_url'))
			transport = 'sse' if use_sse else 'stdio'
			transport_kwargs = {}

			if use_sse:

				transport_kwargs['host'] = kwargs.get('host', '0.0.0.0')
				transport_kwargs['port'] = kwargs.get('port', 3000)

			if 'function_kwargs' in kwargs:

				import json

				try:
					function_kwargs = json.loads(kwargs['function_kwargs'])
					transport_kwargs.update(function_kwargs)

				except json.JSONDecodeError:
					transport_kwargs['function_kwargs'] = kwargs['function_kwargs']

			client = MCPClient.from_applet(applet, transport=transport, **transport_kwargs)
			server_type = 'SSE' if use_sse else 'stdio'
			print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üöÄ Starting {server_type} MCP server for {bundle_id}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

			if use_sse:

				host = transport_kwargs.get('host', '0.0.0.0')
				port = transport_kwargs.get('port', 3000)
				print(f'{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üì° SSE MCP server will be available at: http://{host}:{port}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
				print(f'{cls.GRAY if cls.SUPPORTS_COLOR else ""}   - SSE endpoint: http://{host}:{port}/sse{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
				print(f'{cls.GRAY if cls.SUPPORTS_COLOR else ""}   - MCP endpoint: http://{host}:{port}/mcp{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

			server_args = [client.command] + client.arguments

		except Exception as exception:

			logger.error(f'Could not create MCP server for {bundle_id}: {exception}', exc_info=True)
			quit()

		try:

			env = os.environ.copy()
			env.update(client.environment_variables)

			subprocess.run(server_args, env=env, check=True)

		except subprocess.CalledProcessError as error:
			logger.error(f'MCP server failed with exit code {error.returncode}')
			quit()

		except KeyboardInterrupt:
			print(f'\n{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üëã MCP server stopped{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
			quit()

	""" Utilities """

	@classmethod
	def get_kwargs(cls, ignore_unknown: bool = False) -> dict[str, str]:
		"""
		Returns a dictionary of kwargs by converting the args
		passed to `interlinked`

		If any of the args is invalid (e.g. `interlinked 9`) and `ignore_unknown` is `True`, the function will
		log an error and quit

		@param ignore_unknown(bool): (optional) if set, unknown arguments will not raise an exception
		@return (dict): a dictionary containing argument names and their values
		"""

		kwargs: dict[str, str] = {}

		# if the second arg is a number (e.g. `interlinked screen_radars 1`)
		# start reading kwargs after that
		for arg in sys.argv[(3 if len(sys.argv) > 2 and (sys.argv[2].isnumeric() or sys.argv[2] == 'all') else 2):]:

			# e.g. `--name=` or '--'
			if arg.startswith('-'):

				key = arg[2:] if arg.startswith('--') else arg[1:]

				if '=' in key:
					key, value = key.split('=')

				else:
					value = None

				if value in {'true', 'True'}:
					value = True

				elif value in {'true', 'True'}:
					value = False

				elif value and value.isnumeric():
					value = int(value)

				kwargs[key] = value

			# e.g. `--name applet`
			elif kwargs and list(kwargs.values())[-1] is None:
				kwargs[list(kwargs.keys())[-1]] = arg

			# e.g. `applet`
			elif not ignore_unknown:

				logger.error(f'I\'m not sure what argument "{arg}" is. Try again with `--[argument_name]={arg}`')
				quit()

		return kwargs

	@classmethod
	def get_cli_configuration(cls) -> dict[str, Any]:
		"""
		Loads the CLI history and user preferences into memory

		@return (dict):
		"""

		if not os.path.exists(cls.CONFIGURATION_FILE_PATH):
			return {}

		with open(cls.CONFIGURATION_FILE_PATH, 'r') as file:

			content: str = file.read()

			# handle empty file case
			# unsure why or how this happens
			if not content.strip():
				return {}

			cli_configuration: dict[str, Any] = None

			try:
				cli_configuration = json.loads(content)

			except Exception as exception:

				logger.error(f'Could not read the contents of {cls.CONFIGURATION_FILE_PATH}. Please delete the file', exc_info=True)
				return {}

			# load history into memory
			for prompt in cli_configuration.get('prompts', []):
				readline.add_history(prompt)

			return cli_configuration

	@classmethod
	def save_prompt(cls, prompt: str) -> None:
		"""
		Appends a given prompt/input to history
		"""

		readline.add_history(prompt)

		cli_configuration: dict[str, Any] = {'prompts': []}

		if os.path.exists(cls.CONFIGURATION_FILE_PATH):

			with open(cls.CONFIGURATION_FILE_PATH, 'r') as file:
				cli_configuration = json.loads(file.read() or '{}')

		if 'prompts' not in cli_configuration:
			cli_configuration['prompts'] = []

		cli_configuration['prompts'].append(prompt)

		with open(cls.CONFIGURATION_FILE_PATH, 'w') as file:
			json.dump(cli_configuration, file)

	""" Utilities """

	@classmethod
	def get_is_process_running(cls, name: str):
		"""
		Checks if there is any running process that contains the given name
		"""

		import psutil

		for proc in psutil.process_iter(['name']):

			try:

				if name.lower() in proc.info['name'].lower():
					return True

			except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
				pass

		return False

	@classmethod
	def get_or_prompt_applet_kwargs(cls, applet: 'Applet', existing_kwargs: dict[str, Any]) -> dict[str, Any]:
		"""
		Prompts the user for missing Applet function kwargs and returns the complete kwargs dict

		@param applet(Applet): The Applet instance
		@param existing_kwargs(dict): Already provided kwargs from CLI configuration
		@return(dict): Complete kwargs dictionary
		"""

		if not applet.kwargs:
			return existing_kwargs

		# download the applet files if not already done
		if not applet.path or not os.path.exists(applet.path):
			try:
				applet.get_tools(function_kwargs={})

			except Exception:
				pass

		# should never happen
		if not applet.path or not os.path.exists(applet.path):

			print(f'{cls.YELLOW if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è Could not download {applet.name}{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
			quit()

		files: list[dict] = applet.get_files_for_path(path=applet.path)

		# collect all unique kwargs needed across all functions
		unique_kwargs_needed = {}  # {arg_name: {description, is_sensitive, functions_using_it}}

		for function_name, expected_kwarg_names in applet.kwargs.items():

			if not expected_kwarg_names:
				continue

			# find the function definition to get argument details
			function_arguments: list = []

			for file_data in files:

				if file_data.get('type') != 'backend':
					continue

				for function_definition in file_data.get('tools', []):

					if function_definition['name'] == function_name:
						function_arguments = function_definition.get('arguments', [])
						break

				if function_arguments:
					break

			# check each expected kwarg
			for expected_kwarg_name in expected_kwarg_names:

				argument_info = None

				for argument in function_arguments:

					if argument['name'] == expected_kwarg_name:

						argument_info = argument
						break

				# only collect required arguments
				if not argument_info or not argument_info.get('optional', False):

					if expected_kwarg_name not in unique_kwargs_needed:

						unique_kwargs_needed[expected_kwarg_name] = {

							'functions_using_it': [],
							'description': argument_info.get('description', '') if argument_info else '',
							'is_sensitive': any(keyword in expected_kwarg_name.lower() for keyword in ['password', 'secret', 'key', 'token', 'auth']),
						}

					unique_kwargs_needed[expected_kwarg_name]['functions_using_it'].append(function_name)

		# filter out kwargs we already have
		missing_kwargs: dict[str, Any] = {}

		for argument_name, argument_details in unique_kwargs_needed.items():

			# check if we already have this kwarg (in global format or function-specific)
			has_kwarg: bool = False

			# check global format first
			if existing_kwargs.get(argument_name):
				has_kwarg = True

			else:

				# check if it exists in any function-specific format
				for function_name in argument_details['functions_using_it']:

					if existing_kwargs.get(function_name, {}).get(argument_name):
						has_kwarg = True
						break

			if not has_kwarg:
				missing_kwargs[argument_name] = argument_details

		if not missing_kwargs:
			return existing_kwargs

		# prompt user for missing kwargs
		print(f'\n{cls.BOLD_GREEN if cls.SUPPORTS_COLOR else ""}üîê {applet.name} requires details from you.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')

		updated_kwargs = existing_kwargs.copy()

		for argument_name, argument_details in missing_kwargs.items():

			description = argument_details['description']
			is_sensitive = argument_details['is_sensitive']
			functions_using_it = argument_details['functions_using_it']

			# create a user-friendly prompt
			prompt_text: str = f'Enter {argument_name}'

			if description:
				prompt_text += f' ({description})'

			elif len(functions_using_it) > 1:
				prompt_text += f' (used by {len(functions_using_it)} functions)'

			elif len(functions_using_it) == 1:
				prompt_text += f' (for {functions_using_it[0]}())'

			prompt_text += ': '

			try:
				value = input(prompt_text).strip()
			except (EOFError, KeyboardInterrupt):
				print(f'\n{cls.YELLOW if cls.SUPPORTS_COLOR else ""}‚ö†Ô∏è You stopped early. Some functions may not be available.{cls.LINE_END if cls.SUPPORTS_COLOR else ""}')
				break

			# store in global format (this is what get_tools supports as "option 2")
			if value:
				updated_kwargs[argument_name] = value

		return updated_kwargs


class Spinner(threading.Thread):
	"""
	Displays loading animation in terminal

	To start animation:
	```
	thread = Spinner()
	thread.start()
	```

	To stop animation:
	```
	thread.stop()
	```
	"""

	_stop: threading.Event = None

	def __init__(self):

		super().__init__(target=self._start)
		self._stop = threading.Event()

	def stop(self):
		self._stop.set()

	def _start(self):
		"""
		Displays loading animation
		"""

		import time

		animation_index: int = 0
		animation_chunks: str = '‚†ã‚†ô‚†π‚†∏‚†º‚†¥‚†¶‚†ß‚†á‚†è'

		while not self._stop.is_set():

			sys.stdout.write(animation_chunks[animation_index % len(animation_chunks)])
			sys.stdout.flush()

			sys.stdout.write('\b')
			time.sleep(0.05)

			animation_index += 1


if __name__ == '__main__':
	CLI.main()