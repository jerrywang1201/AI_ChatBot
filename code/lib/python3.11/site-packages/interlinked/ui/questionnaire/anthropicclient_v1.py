from fastapi import HTTPException

from interlinked.ui.schemas import Questionnaire, QuestionnaireResponse
from interlinked.core.clients.appledirectoryclient import AppleDirectoryClient, Person


def get_response(questionnaire: Questionnaire) -> QuestionnaireResponse:
	"""
	Returns questionnaire response for Anthropic
	"""

	next_page: str = None
	back_page: str = None

	error_message: str = None
	eligibility: dict[str, Any] = None

	# determine the next step and previous step based on the current page and form data
	if questionnaire.current_page is None:
		next_page = 'use_case_types'

	elif questionnaire.current_page == 'use_case_types':

		use_case_types: list[str] = questionnaire.questionnaire.get('use_case_types')

		# make sure we have values
		if not use_case_types or len(use_case_types) == 0:
			raise HTTPException(status_code=400, detail='Missing use_case_types (list)')

		if 'red_teaming' in use_case_types:
			next_page = 'separate_account'

		else:
			next_page = 'critical_code_bases'

		back_page = None

	elif questionnaire.current_page == 'critical_code_bases':

		if 'code_completion' in questionnaire.questionnaire.get('use_case_types', []):
			next_page = 'open_source'

		else:
			next_page = 'pii'

		back_page = 'use_case_types'

	# elif questionnaire.current_page == 'environment':

	# 	next_page = 'pii'
	# 	back_page = 'critical_code_bases'

	elif questionnaire.current_page == 'open_source':

		next_page = 'pii'
		back_page = 'critical_code_bases'

	elif questionnaire.current_page == 'pii':

		if questionnaire.questionnaire['pii'] in {True, 'true'}:
			next_page = 'no_pii'
		else:
			next_page = 'tiers'

		back_page = 'critical_code_bases'

	elif questionnaire.current_page == 'tiers':

		next_page = 'use_case'
		back_page = 'pii'

	elif questionnaire.current_page == 'use_case':

		next_page = 'review'
		back_page = 'tiers'

	elif questionnaire.current_page == 'review':

		next_page = 'review_1'
		back_page = 'use_case'

	elif questionnaire.current_page == 'review_1':

		next_page = 'coding_agreement'
		back_page = 'review'

	elif questionnaire.current_page == 'coding_agreement':

		next_page = None
		back_page = 'review_1'

	else:
		raise HTTPException(status_code=400, detail='Invalid current_page')

	questionnaire_steps: dict[str, dict] = {

		'use_case_types': {
			'step': 'use_case_types',
			'type': 'dropdown',
			'subtitle': 'Usage policies vary based on how you plan to use Anthropic.',
			'elements': {
				'question': 'What do you plan on using Anthropic for?',
			},
			'options': [
				{'key': 'productivity', 'label': 'Productivity', 'description': 'AI writes emails, brainstorm plans, and more.'},
				{'key': 'code_completion', 'label': 'Coding', 'description': 'AI writes code, fixes bugs, and more.'},
				{'key': 'distillation', 'label': 'Distillation', 'description': 'Fine-tune smaller models.'},
				{'key': 'internal_use', 'label': 'Internal Use', 'description': 'Build tooling and automation.'},
				{'key': 'red_teaming', 'label': 'Red Teaming', 'description': 'For security teams evaluating safety.'},
			],
		},
		'critical_code_bases': {
			'step': 'critical_code_bases',
			'type': 'confirmation',
			'elements': {
				'question': 'Critical Code',
				'description': 'You agree that you will **not** use Anthropic with critical code. This refers to specifically designated source code, such as FairPlay or Secure Enclave Processor firmware.',
			},
		},
		'separate_account': {
			'step': 'separate_account',
			'type': 'information',
			'elements': {
				'question': 'Account Needed',
				'description': 'To use Anthropic for red-teaming, you will need a dedicated account. Contact legal-GenAI-3P@group.apple.com for the next steps.',
			},
		},
		# 'environment': {
		# 	'step': 'environment',
		# 	'type': 'tabs',
		# 	'subtitle': 'Authentication with Anthropic varies based on where you will be using Anthropic',
		# 	'elements': {
		# 		'question': 'Where do you plan on using Anthropic?',
		# 	},
		# 	'options': [
		# 		{'key': 'development', 'label': 'Development', 'description': 'From my Mac'},
		# 		{'key': 'production', 'label': 'Production', 'description': 'Not available yet', 'disabled': True},
		# 	],
		# },
		'pii': {
			'step': 'pii',
			'type': 'tabs',
			'subtitle': 'Privacy sensitive data includes data from study participants from health studies or who are children and Apple user data, including when the data has been aggregated or otherwise de-identified. For additional information review the [PSD policy](https://cloudtech.apple.com/documentation/getting-started/privacy-sensitive-data-types).',
			'elements': {
				'question': 'Is the data classified as [Privacy Sensitive](https://cloudtech.apple.com/documentation/getting-started/privacy-sensitive-data-types)?',
			},
			'options': [
				{'key': 'true', 'label': 'Yes', 'description': 'My data is Privacy Sensitive.'},
				{'key': 'false', 'label': 'No', 'description': 'No sensitive data.'},
			],
		},
		'tiers': {
			'step': 'tiers',
			'type': 'confirmation',
			'elements': {
				'question': 'Tier 0-1 Data',
				'description': 'You agree that you will **not** input any data elements in [Information Security Classification](https://infosec.apple.com/apply-security-requirements/governance-resources/data-classification-tiers) Tier 0 or 1 in your prompts.',
				'additional_info': 'If you have questions, we\'re here to help at [#help-interlinked](https://slack.com/app_redirect?channel=help-interlinked).',
			},
		},
		'crawling': {
			'step': 'crawling',
			'type': 'confirmation',
			'elements': {
				'question': 'AppleBot',
				'description': 'Your agree that you will not input [AppleBot](https://pages.github.pie.apple.com/applebot/applebot-sdk/README.html) or crawled data in your prompts. If you want to input crawled data, please follow the process outlined [here](https://confluence.corp.apple.com/pages/viewpage.action?spaceKey=plgAW&title=GenAI+Tools) instead.',
				'additional_info': 'If you have questions, we\'re here to help at [#help-interlinked](https://slack.com/app_redirect?channel=help-interlinked).',
			},
		},
		'no_pii': {
			'step': 'no_pii',
			'type': 'information',
			'elements': {
				'question': 'Privacy consultation required.',
				'description': 'AIS and Privacy Engineering have not approved third-party hosted models for processing privacy sensitive data. Please file a [secondary data use request](https://confluence.sd.apple.com/display/UserPrivacy/Secondary+Data+Use) to evaluate your use case.',
			},
		},
		'use_case': {
			'step': 'use_case',
			'type': 'textarea',
			'elements': {
				'question': 'Briefly describe your use case.',
				'description': 'Describe how you plan on using Anthropic.',
				'placeholder': 'e.g. I am prototyping an internal tool for classifying Radars',
			},
		},
		'review': {
			'step': 'review',
			'type': 'review',
			'elements': {
				'statements': [
					{
						'id': 'no_pii',
						'title': 'No Personal Data or Privacy Sensitive Data',
						'description': 'I will not include any [Personal Data](https://infosec.apple.com/apply-security-requirements/governance-resources/personal-data-types) or [Privacy Sensitive Data](https://cloudtech.apple.com/documentation/getting-started/privacy-sensitive-data-types) in my prompts, including but not limited to names, addresses, identifiers, Slack messages, sysdiagnoses, health data, whether aggregated or de-identified.',
					},
					{
						'id': 'training',
						'title': 'Training or Fine-Tuning',
						'description': 'I will not train, fine-tune, or aid in training a model that is over 150b parameters or one that will be shipped as a standalone model (e.g. on Hugging Face).',
					},
					{
						'id': 'open_source',
						'title': 'Open Source',
						'description': 'I will always confirm with Legal before before making open source one-off contributions.',
					},
				],
			},
		},
		'review_1': {
			'step': 'review_1',
			'type': 'review',
			'subtitle': 'Please review these additional statements',
			'elements': {
				'statements': [
					{
						'id': 'critical_code',
						'title': 'Critical Code',
						'description': 'Anthropic cannot be used with designated critical code.',
					},
					{
						'id': 'black_ultra',
						'title': 'Black/Ultra',
						'description': 'You **are permitted** to use Apple-internal, along with Black/Ultra data and code with Anthropic.',
					},
					{
						'id': 'data_processing',
						'title': 'Data Processing',
						'description': 'All messages to Anthropic and responses are logged and stored by Apple, for security purposes. Your data will be retained indefinitely.',
					},
				],
			},
		},
		'coding_agreement': {
			'step': 'coding_agreement',
			'type': 'confirmation',
			'elements': {
				'question': 'Third Party Model Generative Coding Agreement',
				'description': None,
			},
		},
		'open_source': {
			'step': 'open_source',
			'type': 'confirmation',
			'elements': {
				'question': 'Open Source',
				'description': 'Before adding Anthropic to your workflow, confirm that you will check with Legal before making open source one-off contributions, by indicating in your request Anthropic use, or with the project Champion for OSRB approved projects.',
			},
		},
	}

	# get the data for the next step
	step_data: dict[str, Any] = questionnaire_steps.get(next_page)

	# if this is the final confirmation
	if next_page == 'coding_agreement':

		import pathlib

		BASE_PATH: str = pathlib.Path(__file__).resolve().parent.parent
		STATIC_PATH: str = pathlib.Path(f'{BASE_PATH}/static')

		with open(f'{STATIC_PATH}/third_party_coding_agreement.md', 'r') as file:
			step_data['elements']['description'] = file.read()

	if error_message:
		step_data['elements']['description'] = error_message

	if next_page in {'no_pii', 'separate_account', 'coding_agreement'}:

		next_page = None
		back_page = None

	step_data['back_page'] = back_page
	step_data['has_next_step'] = next_page is not None

	return QuestionnaireResponse(**step_data)
